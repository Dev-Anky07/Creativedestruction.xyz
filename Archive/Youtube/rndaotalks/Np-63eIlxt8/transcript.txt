[ 0:00:06.000 ---> 0:00:06.000 ] Speaker A : Yeah.
[ 0:00:06.000 ---> 0:00:23.000 ] Speaker B : So today we have Lee Bryant. He is an educator and co founder at Postshift, which is startup that helps organizations introduce agile capabilities. Lee, why don't you go ahead and.
[ 0:00:23.000 ---> 0:38:38.000 ] Speaker A : Introduce yourself you thanks Daniel. Yes. So my name is Lee Bryant. I've been involved in sort of social and digital technology within organizations for quite a while, maybe 2020 years or so. And prior to that, like many people in the 1990s, we were sort of playing with the web and trying to build knowledge, sharing distributed systems with that sort of gen of technology. Sort of I'm not a technologist by training, but I've been sort of playing within program and computers since I was about ten years old, which is a very long time ago now. And in fact, my first career was really in politics and activism, did some war journalism, did some campaigning, did some diplomacy and international relations. And actually that's where I first really learned the sort of incredible power of the internet and distributed communications to make a difference. So what we do these days is we help large organizations transform, become more digital, we run big transformation programs. And personally I spend quite a lot of time as an executive educator with some of the business schools really specializing in sort of teaching existing leaders about digital organizations, about what the future of organizations looks like and how they can be sort of digital leaders, I suppose. So deeply frustrating activity sometimes, but also really rewarding when you meet some emerging leaders who sort of come into positions with these ideas and feel frustrated by the lack of progress. So I'm kind of fascinated about DAOs. They're such a sort of a siren song of a wonderful concept or archetype, but I'm equally skeptical about the way in which they interact with human nature and patterns of sort of group behaviors. So I'm very interested to hear from you guys after I give my remarks to start with. So let me just pop up some slides just to give myself a bit of orientation and I will get started. So I think it's an obvious cliche to say that we have really an institutional design problem, not just in companies, but also in government organizations. In NGOs, we have these organizational models which are sort of based on the late 19th century, early 20th century business school thinking, but they are fundamentally unfit for purpose in a sort of time of rapid change. Exponential age, all the rest of it. And I know, I'm sure you sort of agree with that. One of the sort of conventional management thinkers, Gary Hamill, puts it in this way. He says we've got sort of 21st century internet enabled business processes built on a mid 20th century sort of enterprise management process which is really sitting on an architecture from the US railroads in the late sort of 19th century. The only way that we knew to scale when the only tech we had was telegrams is to rigidly standardize and cascade down an organizational chart with managers having direct reports, who have direct reports, who have direct reports. And unfortunately that system is so well baked in to the way that we see business that people have really struggled to come up with alternatives despite the obvious problems that they have. The way that I sort of see this I'm very interested in evolution and to me the corporate structure is like a religious sort of intelligent design concept, right? It's the idea that these managers sitting at the top like gods can actually design everything themselves and then we just do what we're told underneath. But it lacks all of the features of a natural system or an evolutionary adaptive system as we might see in nature. I think one of the other issues there is that we've seen huge value capture by management. So we have organizations where pretty ordinary folks are getting paid multimillions a year to sit on top of this empire, soaking up a lot of the value, whilst people on the front line who are having human contact, human conversations, providing real service and care are paid so poorly that they're sort of below the poverty line. Certainly in the US and in the UK that's been the case for a while now. So it's a very imbalanced system and it's one that doesn't really work either for shareholders or for society or indeed for most of the employees in these organizations as well. So I think for me, whatever your politics is, whatever economic models you prefer, I think the lack of a stake that most people have in this system is definitely one of its real weak points. And I know obviously, that's one of the problems that Dows are trying to address. But in terms of what it means for our human capacity we talk about artificial intelligence today, but really we've spent the last hundred years developing artificial stupidity. We've taken well educated, smart, sensible people who at home are quite capable of standing up an Android distro or maybe installing a Unix distro on their computer, solving problems for themselves and as soon as you put them in this sort of workplace they develop this learned helplessness, they become functional idiots, right? And they need to be trained on everything from Microsoft Outlook upwards and that seems like a really poor use of human potential to me. And what's interesting as well is that the managers who populate this system are basically a fungible and almost limitless resource, right? One thing we don't have a shortage of in the world today is middle aged men with strong opinions who like to tell people what to do. So economic models of sort of demand and supply would suggest that they are paid the least. And in fact, people who can do real human skilled stuff should be paid more. But actually the reverse is the case, which is weird. And I think the other thing about these systems is that it's not just that they're not very human. They're also not very automatic or automated either. What we've done is we've created these sort of almost sort of Heath Robinson machines which are made out of humans, so they're neither fish nor foul, right? They're neither smart and automated machines, but neither are they human in shape and dynamics either. So they sort of the worst of both worlds in some respects. So the question obviously is can we coordinate work without the sort of costly analog management system sitting on top? And I think before we try and answer that, we should first of all acknowledge the strengths of the existing system. And I think one strength of bureaucracy is that it has the advantage of giving everyone a place. So if you go back to verbarian notions of bureaucracy in sort of social and political science, one of the advantages was in fact that even if you're low down the hierarchy, you have a role, okay? And you can't just be told to go and buy the boss a sandwich or do this or do that because you have a place in the system. So that's in a way a protection against autocracy in one respect. I think the other thing is that hierarchy is legible, right? We can navigate it. It makes it easy to find where we need to go to get things done, even if that takes time and is quite inefficient. And also whenever we've experimented with totally flat structures, often it brings out the worst in the most sort of socially dominant people in those structures. There's a very famous paper from, I think the early 70s called The Tyranny of Structurelessness which actually comes from, I think, the feminist movement. But it says when we have these pretend flat organizations, in fact they are super dominated by those kind of extroverts who are able to manipulate people and tell people what to you know, there are no easy answers in this respect. And I think recently, in the last decade or so, we've seen a bunch of alternative models emerge. You've got the sort of famous spotify sort of agile squads and tribes model, which is really overstated because their model is a lot less simple than that. And you've also got things like holocracy as a system. But the irony to me of systems designed by geeks like me is that they often become too bureaucratic in their own right. So I personally find full accuracy way too tedious and bureaucratic as an operating system for organizations. So the question that I'm really interested in is how can we combine sort of self management, local autonomy, but also with some strategic coordination at scale? And how can we run that in a simpler way? How can we make better decisions? And how can we overcome this basic Stone Age mentality of running an organization through meetings and emails which is honestly most of the people I work with on a day to day basis, that's their life, right? It's 8 hours of Microsoft teams calls plus a thousand emails, and most of it is complete nonsense. And I think what that suggests to me is that one of the reasons for that is that managers are good at sociopolitical structure, right? They're good at presence, they're good at telling people what to do. They're less good actually at doing the work themselves or writing things down or building knowledge systems or coding or whatever it might be. And so they have a real advantage in that kind of system. I think overall, I'm a bit of an optimist. I do believe that people can do extraordinary and incredible things if they have to, if they're motivated to do so, and if we get out of their way. So these guys on the picture, they sort of flew into space with software designed by some female software developers who only had punch cards and reams of paper. They trusted the calculations, their life depended on it, and their whole ship probably had less tech than a low level Android smartphone. And today, what we're seeing is loads of other examples where people have no choice but to innovate and do things in a better way. So you can look at Ukrainian defenders against the Russian invasion today. You could look at Bosnian defenders 30 years ago against similar attack by Serbia. And these are people who are literally rewriting accepted military doctrine and doing things with last gen weapons that nobody thought was possible. Why? Because no one's told them they can't do it. It's like the Steve Wozniak story. And also because they absolutely have to. So when people have the motivation, they will do anything to use the tools at their disposal to achieve what they need to do. And the other thing that gives me hope is when you look at areas like sport athletics, if you look at the state of the art today in athletics, it's so far ahead where the same people were achieving 50 years ago. Not because the tech has changed. Maybe their diet is slightly better or some of the sports science is better, but fundamentally, it's the power of grinding it out in an evolutionary improvement process. Just getting a little bit better, a little bit better. Eventually you get to sort of Usain Bolt levels of success or some of the amazing sort of gymnastics we've seen in the last few years. So I think what I'm interested to bring into the discussion really is how we create the conditions for emergence and for evolutionary improvement, rather than this sort of dead old model of intelligent design within the corporate hierarchy. And one of the reasons why that matters is that you can't do new things successfully with that old structure. So one of the fantastic stories right now in the automotive sector is Volkswagen's perpetual failure to build a software organization within a traditional German corporate entity. They've spent limitless amounts of euros on this, and it simply fails every time. Because to create software, you also need to be a bit like software, right? You need to have a slightly more flexible configuration. And I think what I love about evolution is this idea that you can create, like a flywheel for evolutionary improvement, small, autonomous, independent agents, whether they're people or small teams, all fighting for their own fitness function, but within a coevolving ecosystem. That sort of model or that template is incredibly powerful in nature and in all aspects of sort of human social relationships as well. So I think our organizations do need sort of agile, adaptive attributes, tight feedback loops, learning structures, all of these things. But also evolution depends on having great predators, fierce competition, and an openness to the rest of the ecosystem. And that's something that the largest companies today don't have, actually, because for all of the talk about free markets and competition, really what they're seeking is monopolies and oligopolies and protected positions, so they can just sort of milk the system that way. So a lot of the work that we do, we sort of do some diagnostics around adaptive attributes in an organization. And I have to say, one of the most important is decentralization. I just think as a working principle, it's so fundamentally important. And I think that's where I'm on common ground with you guys. If we want to design a modern organizational operating system, that's got to be an absolutely key feature. So it's not just a lack of hierarchy. It's actually mindful autonomy, local coordination, distributed collective intelligence and feedback systems everywhere, so that we can improve all of the components of this kind of system. But it's not just about people being decentralized. We also need tech and processes and systems to be decentralized as well. So a web of APIs, a web of interfaces, a web of small pieces loosely joined, almost a sort of organizational version of a sort of microservices architecture. And I think what's interesting for me is that this is not a new principle, right? So before the development of these big, solid organizations, we've had lots and lots of examples of decentralized social systems working very, very well. The money sharing system that's called Hawala in sort of East Africa and Asia, it's a peer to peer system where I pay somebody $10 in Portugal and someone pays my family $10 in DACA or wherever it might be. And it's based on trust, it's based on social connections, but it's incredibly low friction, very low cost, and it works quite well. Same with other examples of social capital. The famous studies of sort of Jewish diamond traders in Amsterdam who could just put a bag of gems on someone's desk and not even examine them because they were all so linked that you simply didn't need to worry about exploitation or bad behavior. And we see these examples through history. It's a very resilient model of getting things done for people. Now, recently in business, we've had people like Frederick lalou writing about self managed organizations and how we can create those, but they all tend to depend on having a visionary leader who allows that space to develop. And what I want to see is how we go beyond that and create systems and archetypes for our organizations that just do that, because that's how they function. There is an emerging model in China. You've probably come across a very dynamic enterprise that's quite studied in the literature. They have a model that they call rendan hei, which is essentially based on mutual obligations and peer to peer contracts between teams and people in the organization. And there's sort of a general category of firms now that we call deda digitally enhanced directed autonomy. So very decentralized, very autonomous, but with some strategic direction at the same time, based on what the market needs. These organizations are doing super well. They are fiercely competitive both internally and externally. So they may be slightly unpalatable for European workers in particular, but they're doing well even in the US. So they bought GE appliances and brought that back to life. They've bought some foundries and engineering companies in Germany and brought that back to life. So it's kind of an interesting model. It's by no means perfect, but it's probably the closest to a working platform ecosystem corporate model that I've seen recently. So this raises the question I won't go into this because we don't have time to cover it in detail, but it's an interesting one if you want to read up on it. So this is where I hope I don't diverge too far from your thinking or your comfort zone. But what about crypto? What about on chain governance? What about dows? The idea of dao is obviously really intriguing, and perhaps this is the route to decentralized organizations that can be steered by communities and groups of people without the sort of dead hand of management. I also very much like the idea of algorithmic governance, and I like the idea of smart contracts as well. These are very attractive ideas. As I said, with this higher Rendon hay model, peer to peer mutual agreements and accountability is a really robust way of joining things together laterally within an organization, rather than relying on vertical alignment through a hierarchy. And if you look at some of the problems in business, look at audits and look at financial management, we've seen lots of scandals around audit failures in recent years. We've seen wirecard as a huge scandal in Germany, for example. And really, there's no reason that audits should be this occasional exercise with some accountants walking in and asking for paper and spreadsheets. It should just be a feature of the system. 24/7 throughout the data should be auditing itself, right? And we should be having sort of algorithms that trap failure codes or failure states and so on and so forth. And similarly with the way we do compliance in organizations, why is that not just a feature of the services and platforms that we use? Why do we do it manually by teaching people what bad behavior looks like and then waiting for them to do it and then telling them off and reviewing our processes, as the banks always say when that happens. So I think there is a lot of potential here for the ideas behind DAOs. And I think actually more broadly than just thinking about Blockchains and thinking about DAOs, I think we have the potential to give people incredible organizational superpowers using these modern tools and technology. But I think we should use these tools to augment human intelligence and activity, not to automate it away or to replace it. So in other words, I'm very much of the opinion that we should be equipping people with all of these wonderful tools and letting them do the steering and the guidance. Because fundamentally organizations are social constructs. Whether we're pursuing profit or civic goodness or something in the middle, they're social organizations with a social purpose. Money is also a social object as well. And what excites me about the current state of the art and maybe the coming together of AI and some aspects of crypto is think about how the written language evolved human society. We have the ability to write a few sentences, 18 bytes of sort of text, right, that can unfold in a reader's mind into a whole world of beauty and complexity because we're referring to common archetypes and things we all understand. So written language is almost like a compression algorithm, right, for sharing information. It's incredibly powerful. And then look at what happened to software. Software went from I was dabbling with assembly language when I was a kid, incredibly painful thing to do. But now you can put a single line into a command line interface and it can unfold a whole framework with libraries and templates and you just need to play with it and customize it to your heart's content. So we're sort of moving up the value chain with our use of language and with our use of software. And prompt engineering in AI is just another stage of that. The idea that we can type a few words into a CLI and it can actually build a whole thing for us. I think that in organizations, if we think of our organizations as being a bit like software, these spells and incantations that we can type into command lines or into a chat GPT interface will enable us to instantiate a finance department right, or a supply chain or a whole sort of new service area within an organization. Because the background activities are known, the data is known, the sort of technology architecture is known. And so I think we are genuinely on the cusp of having these sort of written superpowers where a small team of 1220 people can build a sort of global organization that's doing billions of dollars in revenue. And I think that's super exciting, right? So then the question is just how do we get there from here? Which is a much more difficult problem. But I think there are some worries and concerns I have in particular about the whole sort of Dao model. I think the fundamentally transactional nature of token economics and token based governance is something that I personally have some reservations about because I think the very best examples of human endeavor that I've come across, the very best teams within a team, they're totally nontransactional, right? They're just fighting for each other. They're supporting each other shoulder to shoulder and just doing what needs to be done. They're not always thinking about who's got votes and how does the bureaucracy work and all that kind of stuff. So that's one reservation that I've got. I think the other reservation just really comes from the whole sort of car crash of crypto and the lack of sort of meaningful use cases we've found in the last ten years or so for blockchain stuff. Crypto markets, in my view, are largely sort of rigged. They're not really decentralized. It's a wash trade full of whales. There's a whole ton of money laundering going on in the background of that. There's a lot of problematic aspects to that and I don't really buy into the fact that these are equitable distributed systems for the most part. Some are, some quiet markets might be, but on the whole, not necessarily. And obviously, if you know a bit about tech at first, blockchains are exciting because it's a beautiful concept, but it's just a database, right? And it's still subject to garbage in, garbage out. So it can't be the arbiter of truth if I tell it a lie unless somebody can actually do the verification on my behalf. So there's a lot of issues with there that I find, and I think these are sort of downsides of a trustless or a trust free system. But the other bit that I do find very naive, honestly, is the idea of coders law, right? It made me laugh when Ethereum got to their first fork because if you meet the devs, okay, they're decent devs, but they're not geniuses, right? And they made some mistakes and that led to some very serious consequences. And even today we're still seeing these like this tornado cash governance car crash that happened, I think it was last week, just coding problems leading to somebody being able to take all the votes and effectively take control of the organization. And I feel for people like Vinay Gupta, I don't know if you know him, but he's got a company called materium which is trying to sort of link physical objects with blockchain ownership systems and even he's frustrated and feels that we need some law. But what's interesting about law is that law is by design, messy, right? It's not structured, it's incredibly self contradictory. It's a mess of precedents, customs and lots and lots of individual components. And that's by design because human life, human society is also messy and can't be simply organized into a coding framework. And I think that's actually a feature, not a bug. And so I do think that people seeking to pursue the sort of coders law line are going to find barrier after barrier, blockage after blockage along the way. Fundamentally, when people have no relationship, if we're talking about a decentralization based on anons on the internet, they will behave very badly. They will exploit each other, they will use every trick in the book to steal things that's just, unfortunately, human nature. I think one of the big lessons, really, from the sort of early social media world is that we used to live in this wonderful utopian blogging world where everyone was nice to each other, we all knew each other. And then suddenly Facebook and Twitter came along and they aimed for a global community, a massive scale, sort of flat network where we could all talk to each other. But because nobody knew each other, it had a very negative and damaging effect on our societies. And many of our children are sort of still living with the implications of that having been damaged by the whole Instagram thing and Facebook and so on. So I think sometimes what we don't need is infinite scale and anonymity and a lack of skin in the game. Sometimes what we need is to start small and actually build networks and groups and teams of common purpose and then start to sort of scale those up or grow them from there. So I personally don't want to give up on interpersonal trust. I don't want to create proxies for trust. What I would like to do is to use technology, in fact, to increase the surface area, increase the social surface area that creates the opportunities for us to sort of build trust between each other. And I think that's one of the things that we might consider exploring as an alternative avenue towards decentralized systems. For me, as I said, the best teams are really explicitly nontransactional. They create spaces in which people can do their best work. They can work together without worrying about advantage, without worrying about these distortions of sort of economics. And I think lots and lots of the history of social studies and social science is all about the sort of paradoxes of group behavior, the tragedy of the commons, for example, all of the failures of very well meaning sort of utopian systems that don't really understand how human nature works. One of the things that worries me today around AI is if you go back to the literature of Milan Kundera, who wrote these beautiful books like The Unbearable Likeness of Being, all of these books are fundamentally about this paradox that the people who created sort of the Czech communist system in the beginning were all utopian idealists. And of course they create a system, they vest authority in the system, a bit like with crypto or a bit like with AI, and then say, coders law, the system rules over people. And then obviously the first thing the system does is it goes and hunts down all of these idealist utopians like Milan and puts them in prison or gets rid of them. So I really am very wary of any system that takes, if you like, sovereignty over people, I like people to be on top the whole time, and I think there's no reason why we can't achieve that. So I don't want to Ratle on, I want to leave some time for us to have a little chat. But just to summarize, I guess, where we are in terms of what we do in our thinking, I think the way that I would tackle this problem personally is start small. The power of small teams is immense today. All of the best examples of innovation tend to come from small multidisciplinary teams about the size of an army squad, right? People that know each other intimately, can fight for each other and get things done. Then what interests me about empowering those teams to own an outcome or own a service or own a component, is that if we want to create scale, what we can do is we can just go up a level of abstraction. So instead of a team of twelve, if we have twelve teams of twelve who are working in a related function, then we hit Dunbar's number of about 100 and 4144, which is about the upper bound on sort of a network that we can understand and know. We can know something about those people. We can be a relatively small world network. And then if you scale that up another level, you're at the sort of size of a department or a small division in a company today. And so with the benefit of technology, doing the heavy lifting of communication coordination, work output coordination, joining things together, I think that we can actually create a very, very simple structure that just sort of fractally scales up from small teams to bigger networks and to bigger I think you know where we need to begin in terms of the design is, as John husband and Hugh McLeod, the cartoonists say, it's a switch from hierarchy, vertically divided systems to hierarchies, if you like, laterally connected platforms and networks. And that should be the base on which we sort of build this structure of small teams. So the other part of what we do is not really controversial, it's not really super new, but it's telling organizations, or sort of reminding organizations that this sort of design archetype of platforms and services, or platforms plus apps, is really a very prevalent design principle today. And so what we really. Want for an organization is to take away all of their sort of internal bureaucracy functions and we want to sort of embed them into a series of services that exist within a platform. We want that to be very sort of heterogeneous microservices architecture. And then we want our small teams, our agile teams on top, to be able to pick these services and these components and build new things with them, right? Because we know the components themselves are safe. They're all tried and tested, they're compliant, they do what you want them to do. But actually you can paint beautiful new pictures by combining these and bundling these in different ways. So that's the sort of organizational, if you like, framework that we feel is a viable alternative to hierarchies. It's a viable base for decentralized systems. And so that's where we sort of begin, build the service components and let small empowered teams do brilliant things with them, paint their own pictures, build their own value propositions. It's actually quite similar to what higher and the data companies are already doing actually in China with their version of the platform model. But we need to maintain it, we need to look after it. We can learn a lot of lessons from the world of DevOps, about continuous integration, about orchestrating services and always seeking to improve them over time so that they evolve. And that's back to this idea of ecosystems that I mentioned earlier where we want our independent agents to all be trying to improve themselves and evolve over time. So that's a key part of the steering mechanism. But also, look, we don't need to worry about AGI and writing Shakespeare or whatever at this point, but we can automate a huge proportion of the basic process work that does take place within organizations. So let's use that automation to sort of augment the power that people have in the workplace. Cover the boring stuff, don't have a bunch of drones typing numbers into Excel spreadsheets. Build a system, for goodness sake, right? And then people can actually focus on the higher value activities, the more human activities, the more creative activities in a more decentralized and autonomous configuration. Obviously we want to quantify the hell out of this stuff. We want to build feedback loops in, we want to use data to guide and to steer and to improve things. But also at the same time, we want to improve the leadership that we have at the sort of meta coordination level. So I may have come across as slightly negative about management in general, but there is really a role for leadership, right? So if you look at sports teams, if you look at army squads or military organizations, I personally know and have met some truly brilliant leaders in those environments, people that others would lay down their lives for, people that if they retired, people would beg them to come back and want to be led by them because they create value. They inspire. They do sort of magical things. And you certainly see this in soccer, right? You can see the same team led by two different people with wildly divergent outcomes. So I think it's good to still focus on the value of human leadership, but it's more around the idea of steering and navigating than it is about just telling people what to do or being the star or being the center of attention. And part of how they need to steer organizations differently is really to focus a lot on decision making. So I know one of the topics in DAOs that's probably a big focus is governance, right? How do you take decisions within groups? And many organizations just work by consensus, which is actually a very hard and difficult and slow way of running an organization. These days, some are moving to a more consent based within certain risk frameworks. So if something is not a hugely risky proposition, just let someone try, okay? And then you can deal with the consequences after. But there are probably ten or twelve commonly used decision making methods which apply to different cases or different levels of risk or different use cases. So we need to sort of get better, I think, understanding how risk modeling and decision making changes in this exponential age that Azimazar talks about in his book, because it really is a very different world. And I think finally, back to the human side, the other thing we need to do is to sort of apply the same sort of employee experience in organizations as we seek to apply in customer experience. Employees are the customers of the organization first and foremost, and if we can create meaningful, rewarding, autonomous, and sort of decentralized experiences for them, then maybe we can get some of the most talented people back into organizations. Because right now that's not where they're going, right? They're working for themselves, or they're doing portfolio careers, or they're doing startups or trading crypto coins or FCS, who knows? But it's a bit of a brain drain for large organizations, and we do sort of need some large organizations. Even Tesla, as an automotive organization has what, 150,000 people or something? It's a large organization. Our physical infrastructure, our energy systems, our governance, all of that. It does need some things to happen at scale. So I wouldn't give up on big old organizations quite yet, even though I sometimes feel like doing so, because it's quite frustrating. So anyway, that was my sort of thoughts and remarks, if you like, and I'm sort of curious to see what you guys think and what wonderful mistakes I've made in talking about DAOs in particular. So, yeah, over to you guys. I'd love to hear what you have to say.
[ 0:38:39.000 ---> 0:39:16.000 ] Speaker B : Excellent, excellent. Thanks so much, Lee. That was very insightful. I really appreciate the holistic approach for assessing the organizations of the future. So, yeah, I have several questions. We'd definitely love to open up to the rest of the audience. I guess I'll just go ahead and kick it off. So you talked about leadership. So what are some things that leaders of organizations should actively be doing to continuously have their organization more agile and continuously adapt to challenges?
[ 0:39:17.000 ---> 0:41:25.000 ] Speaker A : Yeah, I used to think that if we built the tools, it would just naturally happen. So if we built sort of more agile systems in organizations, people would just adapt. But the habits are too deeply ingrained. And so this is why I switched a little bit into leadership education, right? So I spend a lot of time with senior leadership groups in these organizations and I guess you've got to start from where they are. You've got to find a way of translating what they think leadership is into a more modern configuration. So not leaving behind everything and saying that they're irrelevant. So that's where I begin. But I think the conversation needs to be had not on the level of principles or all the rest of it. It's about money and time, right? This is where the conversation needs to be had because the way that many of them work today is so fabulously wasteful in terms of both time and money. It's almost unimaginable the amount that they spend. I mean, I think Gary Hamill estimated something like was it 10 billion or 20 billion a year is wasted in the US just on excess meetings, right? I mean, it's insane, these numbers. So I try and bring it down to that sort of level because that's what they're supposed to care about, right? They're not supposed to care about their own internal politics or who's top dog or when am I going to leave. They're supposed to care about money and time and shareholders. So I think that's the ground on which to have that conversation. But it's a tough one, right. Agile works for tech teams. It's much harder to sort of explain. You've got to broaden the concept a bit into agility and effectiveness for most other teams. So that's what I spend a lot of time doing. But you really have to get these leaders sort of on board and you have to also then empower or inspire the emerging leaders to sort of take some power. So they've got to give some, they've got to take some and hopefully a bunch of people in the middle just retire or disappear because it's a tough problem to solve right now. It's a little bit intractable in some cases. Excellent.
[ 0:41:25.000 ---> 0:41:59.000 ] Speaker B : Yeah. One thing that comes to mind is you talk about having a reciprocal nature between leaders and emerging leaders. I know there's an emerging concept right now in a lot of companies right now called Total experience and it's really involved with seeing how the experience of the actual employees are that state and making things like holistic. So yeah, before we go on to the other questions, have anything to say about that? Have any parallels? Have you heard about this trend?
[ 0:41:59.000 ---> 0:43:57.000 ] Speaker A : Yeah, absolutely. This is the interesting thing, actually, about my I wouldn't call it a career, but my sort of accidentally stumbling into different fields. If you spend time on the front lines in a conflict situation and you're with generals and you're with commanders and stuff like that, you really see the best and the worst of everything. Everything is direct. There's nothing obscured from you. Right. And the very best leaders in that situation are all about their people, and they show bravery. They are honest about their limitations, and people follow them because they protect them, they look after them, and they care about them. And you wouldn't believe the lifelong loyalty that those people have for each other. It's really astonishing. And so if they get together again and try and build a barn or repair a car or something, they bring the same incredible potential to that task because they know each other inside out. And I'm not saying that every day of our working life should be like that, right? But I think we can at least learn some lessons from that. And I think one of the lessons is around this total experience idea that your first customer is your team, right? And you should focus on them, and only after that. Focus on your customers or your stakeholders or your shareholders or whatever. And that's not a common idea right now, but I think it should be. And it's not about football tables and salads or massages. It's much deeper than that. It's much more meaningful than that. And it may also not be consistent with full time jobs. It may not be about a nine to five thing. Right. There's no reason that people need to pretend that they're productive in a linear fashion across an entire working week. You may have people living in different places, you may have people working strange hours, but you need to assemble your forces when you need them. And that takes loyalty, it takes belief, and it takes you really showing them a lot of care and a lot of support as well. So, yeah, I like the idea of total experience as a concept. Excellent.
[ 0:43:58.000 ---> 0:44:16.000 ] Speaker B : Yeah, it reminds me of a Sunzu quote, basically paraphrasing saying, treat your men like your sons and they'll follow you to the ends of the earth. So, yeah, definitely. Okay, great. So I know we have some other questions. George, why don't you introduce yourself and yeah, go ahead and ask your question.
[ 0:44:17.000 ---> 0:44:18.000 ] Speaker A : Okay.
[ 0:44:18.000 ---> 0:44:20.000 ] Speaker C : Can you guys hear me?
[ 0:44:20.000 ---> 0:44:21.000 ] Speaker A : Yes, sir.
[ 0:44:22.000 ---> 0:44:42.000 ] Speaker C : Hi, Lee. It's so nice to see you after something like 18 years. I remember around 2005, we had lots of conversation, and at that time, you was at the absolute leading edge of digital transformation, and you still are. So it's nice to connect.
[ 0:44:43.000 ---> 0:44:47.000 ] Speaker A : Thank you. You look great, by the way. You look better than you did ten years ago.
[ 0:44:49.000 ---> 0:45:26.000 ] Speaker C : So you said a couple of things that well, everything, basically everything that you said I vibe with greatly. But a couple of things that are particularly struck me. One, you mentioned that the mindful autonomy, local coordination, distributed collective intelligence and feedback system everywhere. And that is so dear to my heart. In fact, my current work is focused.
[ 0:45:26.000 ---> 0:45:35.000 ] Speaker A : On collaborative hybrid intelligence emerging from the.
[ 0:45:35.000 ---> 0:46:02.000 ] Speaker C : Human and AI agents in networked teams. So the ideal model that you describe or let's say the one that is close to your heart, do you have any client system that comes close to implement or take your advice to?
[ 0:46:02.000 ---> 0:47:31.000 ] Speaker A : Heart well, actually, I have to be honest, my technology chops are not where they were sort of 1015, 20 years ago. But we are building I'm actually running a project to build some agents, but they're basically like almost search agents that just sort of sit in the background and find things that might be of interest to somebody's learning. Right. Because I'm building a sort of different kind of learning capability development platform thing. So I think there's a lot of potential in that direction. If we can just sort of stop being obsessed with giving will and personality to these bots and just let them do basic tasks, which they're brilliant at, then I think we can advance very quickly in that field. And I think one of the things we try and teach people in leadership today is also that they will be leading a mixed organization. It will be like the bar in the original Star Wars, right? Some are human, some are bots, and some are human bots. Who knows? I mean, that's what Elon Musk is bringing us today on Twitter. And so they need to get comfortable leading a mixed environment that's actually got intelligence beyond just human intelligence. And I think that's an interesting concept and I know that's an area that's close to your heart as well. But yeah, the practice of it. We're not quite there yet, but I think we're getting there.
[ 0:47:31.000 ---> 0:47:46.000 ] Speaker C : Well, I don't want to take much of the time on this call that other people also express, but I will probably follow up with you about this, share some of my work and ask some questions and advice.
[ 0:47:47.000 ---> 0:47:52.000 ] Speaker A : Please do. I'd love to. Love to catch up. Excellent, excellent.
[ 0:47:52.000 ---> 0:47:59.000 ] Speaker B : Thank you, George. Thank you. Lee okay, looks like we have a question from Artem. Please introduce yourself and yeah, go ahead and ask your question.
[ 0:48:01.000 ---> 0:48:29.000 ] Speaker D : Hi, guys. Lee thank you so much. Very interesting talk. Yeah, I've been working in Web Three as a governance governance designer. As I like to say, that's my current job. So I was really intrigued by what you said about earlier about the problem.
[ 0:48:29.000 ---> 0:48:29.000 ] Speaker C : Of.
[ 0:48:31.000 ---> 0:48:53.000 ] Speaker D : Capitalism or corporations being like, the lack of skin in the game and the problem of Dows being that relationships are too transactional. So my question is, do you think it's possible to give this skin in the game without making things transactional. Or maybe it's like a spectrum or dichotomy and you need to find balance.
[ 0:48:53.000 ---> 0:51:30.000 ] Speaker A : I think it's a spectrum, right? So one of the areas that I know in the web two era people put a lot of effort into was reputation sort of quantifying social capital, right? So it's not necessarily transactional in the sense that we have a purse full of tokens and we can spend them and stuff, but the skin in the game is about your reputation in the network. And certainly if you go back to the old Hawala system and the old trading networks that I referred to earlier, everything a person's reputation was a life and death issue, right? People would kill themselves in some cases if they lost their reputation. So maybe reputation is somewhere in the middle between full contact trustful systems like I would dream of on one hand and sort of purely transactional things on the other. But I think the issue of skin in the game anonymity real mutual accountability rather than transaction. It's the tough one, right? It's a tough one to crack. And I just think that human nature is such that, for example, if I go for dinner with someone, I'm always going to be nice to them afterwards, right? I'm never even going to compete with them strongly in business because we sat down together, we've broken bread, we've done wine together and I think this is just how we are wired. It's something quite fundamentally biological in the way that we work. So I like to aim for trustful, but a middle ground is something which is more around reputation, because let's look at the political situation. I'll talk about the UK because I originally was from the Know. It's terrible. People just lie and they lie repeatedly, over and over again. They're proven wrong objectively, and they still are in the media saying the next lie. And people vote for this stuff because they're not educated enough and because even their vote doesn't have skin in the game. I'd like to see a system where if you're going to vote, you maybe need to do a civics class and also your tax for the next twelve months sort of goes up or down, right? Based on the outcome of what you chose to do, there shouldn't be any cost free choices in running a society. So these are all really complex things. I used to actually do some work in civic governance models, like alternative participatory systems and so on. And even there we've been talking about it for 2030 years, but no one's really cracked it. Deliberative assemblies, citizens assemblies, all this kind of stuff. None of it quite hits home in a practical way, so I don't envy your challenge in that role. But maybe reputation is a middle ground between the two. Thank you.
[ 0:51:31.000 ---> 0:51:42.000 ] Speaker B : Excellent, excellent. Great question, very interesting response. Looks like we have two more questions. I'm sorry, I don't know if that's your name? Mpow?
[ 0:51:42.000 ---> 0:51:43.000 ] Speaker A : Yes.
[ 0:51:43.000 ---> 0:51:45.000 ] Speaker B : Please introduce yourself and go ahead and ask your question.
[ 0:51:45.000 ---> 0:51:46.000 ] Speaker A : Yeah.
[ 0:51:46.000 ---> 0:53:07.000 ] Speaker E : Hey everybody. My name is Ryan Lavelle. I'm the founder of Empower. It's really great pleasure to meet you all. Great talk, Lee. Great to be in like minds learning a lot as well today. So thanks for that. Empower's mission to create sort of an exponential scale organization to democratize, impact investing in disruptive clean technology projects, especially in emerging markets. And I've been on this road a few years now. We're about to actually start building some things in the blockchain space finally. And my question to you is a little bit more philosophical. Looking at the events in the last six months as we've seen the sort of tipping point around Chat GPT and exponential explosion of the adoption of mass adoption of AI more prevalent in society, do we feel that this conversation about democratization and decentralized governance is kind of no longer a sort of science project theory? It's it's becoming a lot more urgent and actually perhaps even a mandatory way of going about how these technologies are deployed in society. Keen to hear your thoughts on that.
[ 0:53:08.000 ---> 0:55:06.000 ] Speaker A : Yeah, no, it's a good question. I think we are a bit of an inflection point. Personally. I think that we're probably going to hit a local maxima in terms of the current evolution of LLMs. So I don't think it's just going to go up and to the right from here towards AGI and Sentience. And I don't want Sentience because anyone outside a nightclub with a couple of beers in them can produce the greatest intelligence the world has ever seen outside of maybe octopuses who have a claim to that throne. It's almost cost free and it's an infinite resource. So we don't need we're not lacking intelligence in the world, right? We're just lacking productive uses for it. Most people don't get the opportunity to fulfill it, so it's not like we're short of it. So I very much hope we don't go for Sentience. But the confluence of, let's say, AI automation and better governance with skin in the game and all the rest of it is, I think, an urgent question. Because I have certainty about the risks of scaling. That my instinct. Is to start small. And if we can find something robust and resilient that works for twelve people and then 140 people and then 26,000 people, then we just work on joining them together. I think many of the mistakes we've made over a long period of time actually are about having sort of policies and structures which are just too big and so they're not amenable to social steering. There's always going to be huge minority problems and huge exploitation problems and all the rest of it. So I'm in the favor of not like a green in that sense, but I like start small and then work on the integration and the scaling and the sort of aggregation rather than try and aim for like a Facebook size community and then solve the problems there. But you're right, I think we are a bit of an inflection point in that.
[ 0:55:10.000 ---> 0:55:21.000 ] Speaker B : Excellent, excellent. Okay, great. It looks like we have one more question. Yes Daniel, please go ahead and ask your question. Feel free to introduce yourself for members that are just joining us today.
[ 0:55:21.000 ---> 0:55:22.000 ] Speaker A : Sure.
[ 0:55:22.000 ---> 0:58:11.000 ] Speaker F : So I'm Daniel, part of Dao working across Together Crew, a community analytics tool and then Dao main organizing group. Thanks a lot Lee for the presentation, I really like it. I wanted to first comment a little bit on your perceptions of DAOs and then actually have a question. But to say that I can agree a lot with your condemnations of Dows I would just reframe that as what I'm calling Dows v One. Like these big spaces with direct democracy where people vote based on the number of tokens they have and it's all anonymous and there is no structure or a mess and I think at least the clue up people in the ground have very much realized that there is a lot of developments going towards teams. I think there are well actually two things I would love to ask. So one thing that is being very actively negotiated and I think has huge implications is the idea of permissionless joining that also relates with transparency. So Dow's v One went very radical in that anyone could join because you couldn't know who was a member or not. So the forums were public, the chats were public and people would come in and so on and that has also led to low quality of conversations in many cases because you don't even know who's part and who you should speak with and so on. On the other side it has also opened the door for a bunch of people who would have never made it past the traditional gates to participate here and it has been able to discover a lot of talent and also to very much adapt the conversations for folks who have nontraditional profiles. And as you're saying, the brain drain that corporations have suffered a lot of that has ended up in web free or at least in their spare time if not moving in full time. So at the same time, we ourselves at Arendao, we have a little bit of that structure. And we often struggle with certain personality types that come in and are very disruptive, and you try to handle it, but often they will overpower the organization's ability to handle conflict or to be inclusive, deal with neurodiversity and so on and so on, which are capabilities that are hard to build. So I guess where I'm wondering is if you would have any thoughts related to there is this old saying of like hires low or fires low and self managed organizations have even gone sometimes to the extreme of never firing anyone or these sort of situations and in Dows. I guess I'm going more towards of let everyone in but also kick them out quickly if they cannot observe a set of rules or something. But anyway, yeah, that's kind of like the first question. I would love to hear your thoughts.
[ 0:58:11.000 ---> 1:03:28.000 ] Speaker A : So a couple of confessions or clarifications? One, I wouldn't characterize my remarks as condemnation of Dows because I would like to see DAOs succeed. And in fact, I confess this is my confession. The only reason I'm doing this talk is because actually I like following you on Twitter and I like the positivity and optimism that you bring to this very difficult challenge, plus the fact that you were a chef. I'm a sucker for chefs, right? So I spend a lot of my time touring around, eating at Michelin starred restaurants. And actually the kitchen in a Michelin starred restaurant is another of those extreme examples of teamwork. When it's done right, it can be very exploitative when it's not done right. But when it's done right, it's actually a deeply beautiful thing and shows what people can achieve for not much money as well, actually. So that's my little confession. In terms of the question, I think you're absolutely onto something there. There are no easy solutions to this. But I think one starting point for me is to recognize that a community or a group has a lot of obligations as well as a lot of affordances. And in the real world, a community is something that takes a long time to join, to be accepted in, to develop a reputation in. And it's not something like a network or a social network where you can just join, say some stuff and then go and troll somewhere else. So I think we need some friction. Friction is good in terms of communities because it's a filtering mechanism for those who are passionate to grow the mission or grow the group. So that's the first thing. But the second thing is reputation in a group is also conditional on context. So I may be fantastic about tech, I may be terrible about politics. I shouldn't have a reputation or a position that goes across everything the group does. You should call on different people and different specialist groups for different topics and give them maybe a bit more skin in the game or a bit more authority to make judgments on those questions. Because otherwise you do end up with people who are just generically good at talking and generically good at persuading who tend to carry those debates. So one of the things we used to think about in the old days of reputation and social capital is how you can not just have a single reputation measure, but you have a reputation measure that is actually context specific. So if someone's a brilliant expert on soccer, I don't want to listen to them about tennis, right? So I think, ironically, we need to recreate some of the frictions and limitations of the real world in order to make sure that people who really are involved and have a voice and stick with this do so because they want to. The opposite of that is the inclusive point that you've raised, which is a great point. You want to give a voice to people who are perhaps excluded in other fora or who have a lot to give and a lot of value and so you need to be very inclusive and very supportive. But I think at the same time have quite strong rules about culture, about behavior, about rules of the road so that you don't get bad behavior dominating a governance system. And by the way, this is a feature of every single political system I've ever studied. Going to a local council, you get some of the worst of the worst people in power there because they want to be. That's their little world. And they get power and they get attention and all the rest of it, whereas most normal people can't be bothered with the committees and the rules and all that kind of stuff. So it's a paradox of human organization, actually and I really don't have much in the way of solutions for that one but I would say friction is sometimes a very good thing and constraints are a good thing. Video games don't do a bad job at solving this. So you sort of build your levels, you build your score. You can only squad with certain people at certain levels. They try and match you. So maybe there are some lessons from RPGs and stuff in the video game world that we can bring into this as well. I think there's a lot we can learn from big video games and big video game communities but it's a perpetual human problem, right? All the way from sort of Athenian democracy probably even before there are certain people who like to hear the sound of their own voice and certain people who like to dominate in these kind of groups. So you've got to have some not just amplification mechanisms but also some dampeners, sort of almost automatic dampeners based on posting frequency or based on how people are receiving what somebody is saying. We need to sort of be managing the structure a bit behind the scenes and that's fiendishly complex to do both on a social level and on a code or a technical level as well. But I guess it's something that takes up a lot of time for people like yourself and Artem who are thinking about these these questions. So if you discover good solutions, please call me back and let me know. Thank you.
[ 1:03:29.000 ---> 1:03:30.000 ] Speaker F : Thanks a lot for.
[ 1:03:31.000 ---> 1:03:33.000 ] Speaker A : Excellent, excellent.
[ 1:03:33.000 ---> 1:03:42.000 ] Speaker B : Well, it looks like we are a bit over but really appreciate you speaking with us today, Lee. It was definitely a very insightful conversation.
