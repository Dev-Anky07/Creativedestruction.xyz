[ 0:00:00.000 ---> 0:00:27.000 ] Speaker A : Hey everyone, I'm Daniel from Arundao and today I'm very happy to have with us Matt Barney who has kindly offered to give us a talk on some of his work. He's an expert in psychometrics and been going down the rabbit hole of risk management. So Matt, over to you if you'd like to give us a bit of an introduction about yourself and then go on with the presentation. Thank you very much and thank you for being with us.
[ 0:00:27.000 ---> 0:38:54.000 ] Speaker B : Glad to be with you. I'm an industrial organizational psychologist and I've always worked at the intersection of tech business and psychology and I've been involved with crypto since 2010 when I first read the white paper when I lived in India and working for emphasis. What I want to talk about today is from pure scientific point of view, why should we care about enterprise risks? How might we think about what's similar about other organizations and the science around them? If we're going to do good science around Dows, what kinds of things we need to worry about? And I'll kind of close with hinting at some of the engineering side, but this will be mostly about the science and any of the audience. Feel free to daniel's agreed to be my wingman. Feel free to challenge or ask clarifying questions anytime. I'm happy to interrupt or go into more detail if you like, but I'm going to start out really at the 50,000 foot level. Just saying. I'm approaching this topic from the point of view of helping a Dow achieve its mission vision, its ultimate goals. And there's many, many risks. Way back in the early part of crypto that Mount Gox and more recently, there's plenty of high profile disasters, the earliest the Dao infamously got hacked. The software and tokenomic side of risk is relatively more mature than the organizational team and human risk, which is my focus today and my history, my expertise. So the focus here is about how do we make Dows really robust against different human sources of variation like we do with software and with the financial side of things. I'm going to make the case that we're going to need to reduce those risks in a way that's similar to sophisticated risk management in web two, web one and traditional organizational psych applications of risk management. And I'm going to make a case that we need to think of this in an interdisciplinary way, because no one organizational science has all the answers. Even if a lot of that science was completely relevant to a dow, and I'm not saying all of it is or there's not new things about dows, because there probably are. To make these things on chain immutable composable transparent and real time is crucial to the full potential of dows and overcoming web two, web one and pre internet kinds of risk management. So I'm hoping that you'll leave with a better appreciation for that and get as excited as I am about the potential here. And so I'm going to start with just briefly 100,000ft. Let's put this in perspective before we dive into some of the organizational science, and I'll give you concrete examples that are relevant to influence, for example, convincing people to join your Dow, convincing collaborators and other Dows to work with you. And then I will hint at the very end about new kinds of smart contracts, new kinds of ways to either have psychometric NFTs or immutable storage to make this stuff real and more powerful, with the same kind of governance derisking as we would already have to some degree with the technical and the financial side. So if we just go back to Satoshi's vision, right, in 2008, he wasn't the only one disgusted by inflation occurrency and all the crony capitalistic stuff. Long before Satoshi was writing his white paper, there were other disasters of enterprise risk, including Long Term Capital Management or Nobel Prize winners whose company went bankrupt because they sucked at managing. Then, you know, it wasn't just the scumbags cooking the books then, or last year with many fraudulent things that happened in crypto last year. But Lehman Brothers was also half assed risk management, the largest bankruptcy in human history, also in the same kind of 2008 era. And so these human risks of either crappy skills in risk management or lack of integrity are still plaguing us even now. And so I'm trying to make the compelling case that it's not just those high profile risks, the classic, the Dow disaster, but more subtle day to day risks too, that are trickies of the sort that Vitalan is talking about here, that people are tough to coordinate and tightly in groups. And that was true pre crypto, pre Dao. Perhaps it's even more true in DAOs that have anonymous contributors other than ETH Denver. When do you get to meet each other, right? Or situations like this where you might not even know their real name, you might not see their picture. And these stimuli are typically what we homo sapiens at work need to kind of forge relationships. So these are tricky, non trivial, a bit of wicked problems. And so the same sorts of risks that were powerful pre Satoshi are relevant to why we ought to think about a better kind of science today and why I'm bullish on rndao. And I'm pleased that I was asked to speak today. I wrote a book in 2013 that tries to summarize, even though I'm an organizational psychologist, I've really tried hard to be interdisciplinary and be holistic with the idea that any one business science could have a camera angle on the truth and no one has a monopoly on it. Some are more focused on the big picture, and it might be a stretch for me to call strategy or history a science, but it's relevant to the macro around how you win and what the history has been. The tokenomics, the culture climate. There are a number of different sciences that study these big picture parts that are relevant when you're starting a Dow. And there's others that are much better in the middle of an organization. The flow of work, the creation of smart contracts or in service Dows servicing of customers. The science around industrial engineering and operations research is frankly stronger than my field, which does have something to say about teams. My dissertation was on teams, but my field, for example, is much better and closer at the level of analysis of computer science around the individuals at work. What are the sources of variation between our ears? How does it show up in terms of how we perform? What's the kind of environment around us that we want? And so these microfactors like the engineering concerns or used UIUX human factors concerns, they sit in a context along with the flow and the big picture, the dao to achieve ultimate goals. So I'm coming at this in a hopefully interdisciplinary way to say there's a lot of potential sources of human team organizational variation, together with the technical and the financial. We ought to be holistic. I think if we're going to do Dow governance well, we ought to have a holistic approach where a lot of these sciences are not as mature as the software engineering quality or the financial due diligence, but they're painful sources of risk. In 2008, Koso, which is the Committee of Standards Organizations of the Treadway Commission, is the traditional financial insurance risk people. They tried to have something like I'm showing you here, and if you look under the covers, the emperor is not naked, but he's wearing a tiny G string. It's really not well done. It's not trustworthy in a way that a scientist would say they could hang their hat on it. And so one of the themes in that 2013 book, Leading Value Creation that I found is across the different organizational sciences, both engineering and social, there was a common theme about the place to think about risk management or the biggest sources of risk to achieving goals is bottlenecks. Now, different scientists call these different things constraints bottlenecks. In semiconductors it's called hotspots. But the constraints are the places where there's the biggest gap between what the company, the Dow needs from the work or the team and what it's getting and in the context of the entire value chain. And so part of the model that I created in that book was to say, all right, how do we think about if an organization is a probabilistic human tool set designed to achieve certain goals, in this case, a Dow? There's a mix when we create these organizations of things happen early, early in a process, middle and late. Maybe it's customer acquisition or design and development and delivery. And ultimately there may be financial or customer or in philanthropy, philanthropic outcomes. And it's always a mix of people machine software that do that work. But these have requirements for performance. So if we think about where's the bottleneck, we want to think about what the performance of these different assets are versus what they ought to be to be fully performing. And this way of thinking about organizational effectiveness across disciplines challenges the traditional way we think about an organizational structure. It suggests that we should flip our organizational structures upside down to, say, every support process like, I've worked a lot in HR, or if you've been in finance, right? These are supports to the core processes of a dow and the structure of who reports to whom or who's making what decision is enabling the process to perform to a level that the mission and vision require it to. The culture, leadership. These are all variables that affect the context of those processes. But in orange here, they're all a means to a process product service end that ultimately has cascades or flows up to the ultimate mission and vision. So to simplify that and say, all right, well, how would I find those bottlenecks across the different sciences, across the different parts of a dow? In this case, I want a simplified way of thinking about this. What are the situations where how would I set goals for my dao? How would I cascade them? How would I think about where things are working great where they're not? So I'm focused not on the wrong problems, but on the right ones. Quality, cost, quantity, and cycle time. Qcqc is how I name the model so that you can see the cues or symptoms of where those bottlenecks, those constraints, may be across any of those parts of the dow, any part of the science that might be relevant to it. Quality can be defined as fitness for use. Or in marketing, it might be customer delight. When I was at Motorola, I used to be responsible for Six Sigma. There's Six sigma defect per million opportunities. There's many engineering ways to define this that are common in software, less common to call it quality in finance. But the similar disconnect between whether the work meets the requirements of the people consuming it. The cost is straightforward on chain. Were the resources used to burn, whether it's gas or ETH? Were they worth it compared to the value created at the end and all the normal financial valuation things, you can see where that's relevant. And in the finance concern, what I'm really talking about are antecedents precursors, early warning signs, lead indicators of those ultimate financial customer metrics at the end. So quality, cost, quantity is the volume. If any of you've played with Chat GPT lately and had problems with the servers, or you can't log in, it can't scale. Yet quantity is the volumes flowing through a process. Are they sufficient? And can it scale up and down as the need requires? Some of you remember maybe a year ago when smart contracts cost how much gas ridiculous expense before the proof of stake and before the downturn in the crypto industry. But the quantity is obviously relevant in these processes and cycle time is just the speed. So quality is it doing what it's supposed to do? Is the team working? Is the project performing process, performing and producing outputs or happy customers? The cost, resources, quantity, volume, cycle time, speed this is a holistic way to think where the bottle mix might be and obviously they can also have cascade onto traditional financial measures. So higher quality offerings from a Dao would command a higher price and it comes at a cost. And obviously the higher the cost, the more it bleeds out ultimate economic profit. The more volumes, the more scalable, the more potential services products that a Dow could produce in a certain time frame. And so again, the way to think about these bottlenecks across the organizational sciences, the outcomes, the criterion variables in organizational science studies are a little different for service Dows because the flow of services are either the project or the customer that's being serviced. Some things happen before others and are they being serviced in a timely fashion? Are they happy with the services they're getting from the Dow? Like maybe it's a smart contract audit for example and ultimately do they leave feeling like it was worth it so they want to come back so there's some kind of loyalty component to it? Unlike today's reputation measures in Dows, these are very specific where it's measuring one of these facets at a time. A lot of the reputation measures I've seen seem to lump all of it into one messy indicator. That's not obvious that it's even a measure and it's not obvious how to manage. What this is doing is suggesting where's the bottleneck in a specific way that's actionable. So in a scientific sense you could study it and in a management sense you could pull levers and make the thing better. Here's the product flow where it might be raw material costs or in most Dows it's probably not raw materials, it's probably people. Can I screen the folks that are coming into my Dow or before I give them a grant or manage their work, are they likely to do well as they're doing the work? Are they performing at or above the level that's required? And at the end was the work high quality? Did it burn fewer resources or as many resources as committed in the time frame that was required? So I'm offering a way to think about in organizational science and management the kinds of targets, the outcome variables or the moderators and mediators the lead indicators about risk to ultimate goals. In my field we know a lot for 100 years really about the individual differences of people who are going to be members of your Dow. Some of these are pretty stable and more or less tied to DNA like cognitive ability and some of the personality traits or values. Others are more malleable like the skills to create decentralized business models and tokenomic models that are fair. These are learnable easier to learn or easier to change than things like personality. And that's at the between our ears level that drive our performance in a Dow. At the team and organization level there's a whole bunch of literature that's also relevant to what strategies are truly differentiated and hard to copy or mimic or what kind of culture and climate in your Dow promotes collaboration that would be so important when maybe we never meet our colleagues in a Dow. And so there's quite a bit of science there. I would submit to you that one of those that's super important I would argue maybe more important in DAOs than in a traditional organization is persuasion. If you think know still today crypto is not widely adopted even though since the beginning, since before Bitcoin pizza day people were trying to persuade people to use crypto. The block size wars, right? There's still bad blood over the fact that Roger Veer and friends couldn't persuade the bitcoin maxi types to increase the block size. More recently the controversies about uniswap I don't if know you saw today there was one controversy about MakerDAO and its use of funds from GUSD Tether and influencing misrepresenting some of their assets to the regulator types, the regulators shutting down. One of my colleagues, people I respect, the founder of Library if you know Odyssey, it's the blockchain equivalent of YouTube SEC really not being opaque. Library not able to influence transparency from the SEC for years and it sounds like library may be shut down by the SEC as a warning sign to the industry at least in the United States or within a regular Dao. Just how engaged are voters in making decisions within the Dao? So I would submit there are many complicated persuasion areas and there's good science in this. And so I will just take a moment to highlight what some of these persuasion, these principles of persuasion are. I've worked for many years with professor Robert Cialdini. He's the world's most cited living social psychologist. He's considered the godfather of influence. He's written New York Times bestseller books like Persuasion, Science and Practice. His newest book is Persuasion. All of them are very relevant to DAOs and convincing at least in science of DAOs, convincing people to fund your science, convincing people to join your dao for example. Reciprocity. The first three principles in blue are all about cultivating relationships which I submit to you are slightly harder in DAOs than if it's in real purse, real life and you could go have lunch or dinner, have a cup of tea with them. The first three are all about cultivating relationships with complete strangers like we often do in Dows. Reciprocity is the idea that we all want to give back to those who've given to us first. So when in the ICO craze when people gave free crypto, that might have been perceived as a gift, where people felt some obligation to reciprocate to the DAOs that gave them that. This isn't the same as getting rewarded with crypto or an NFT for doing something that's a reward. This is a proactive gift, and it doesn't have to be tangible or crypto. It can be anything the other person appreciates. The more significant, the more personalized, the more unexpected, the more they're going to feel some obligation to reciprocate. Liking is the idea that we all want to work with, follow the guidance of people that we like, and that like us back. And his newest principle is unity, which is when we use language that unites us, all of us in DAOs, all of us who care about science and want to do good work, in our endow, we're more likely to cultivate relationships because we're part of each other. We're not separated. So these first three are relationship cultivation in the science. These all have excellent peer reviewed proper experiments in labs and experiments in field settings with meta analytics support. So they're very, very trustworthy for dows. The second two are about reducing uncertainty. Consensus is social proof. What do other people just like me, what are they doing? If they're doing it, maybe it's good for me, too. And in situations of preference, that's especially powerful. In matters of fact, the principle of authority is the idea that we all want to follow trustworthy experts. So Bernie Maddoff was a finance expert, but does anyone want to trust him or SBF in the crypto world? Not really. He probably knows something about finance and crypto, but we don't want to follow his advice. So if we have expertise, we need to be the first to admit our weakness and make sure people can understand our expertise. They want to follow our guidance. Plenty of crypto experts, plenty of dow experts that need skills to do this, so people follow their guidance. The last two principles are motivating action. So the first three are about cultivating relationships. The second two about reducing uncertainty. The last two are about motivating action. The principle of consistency is the idea that people are motivated. Once they take a stand, they make a choice, they espouse their values in the dow, they're going to be motivated to remain consistent with that. And pointing this out, pointing out how your recommendation is consistent with their prior values, their prior choices, is likely to help them move in your direction. Last principle is the most primitive. Even single celled organisms follow this, and it's the only one that got the only psychologist to get the Nobel Prize daniel Kahneman. Chaldini calls Daniel Kahneman's idea the principle of scarcity. It's this idea that all of us are much more motivated to avoid losing something in the Tao in life than we are to gaining the same amount. And so if people have something to lose, we would be doing them a favor and they would appreciate it if we're pointing out the truth in the situation. So all of these have a strong ethics component. This isn't about misrepresenting, this isn't about manipulation. It's about wisely educating people to move in our direction. Excellent science. Here I would submit to you highly relevant to DAOs and one example of, like, a psychometric NFT or a psychometric set of smart contracts that could help mitigate the risk of, say, dao founders or dao governance types being able to move the Dao community in the direction of the Dao would be. I helped Bob create a computer adaptive situational judgment test where you have to basically answer questions of how you would persuade ethically in given situations. Computer adaptive testing is a very advanced form of psychometrics when it's used with a kind of rules based AI called automatic item generation, it means you can have hundreds of millions of different questions with minimal effort. And so if people keep taking the test and not doing that well and they want to go learn and get better, they can take the test, get totally different questions, and you still get good information of the sort that we're used to in thermometers and rulers in physical, chemical, biological science. So for a dow leader that wants to be good at governance and mitigate risks of the sort of backlash that MakerDAO had just in the last 24 hours with their recent governance proposal, they would do well to learn. These techniques, mitigate them on chain. And if people don't quite know them well enough, get them coaching and training so that they get better. So this is an example in Chaldini's model you might remember, the principle of authority is not about being the boss. It doesn't interfere with anything about decentralization. It's about expertise. And part of expertise is trust. We know a lot about trust. Trust I think, is a lot of what the reputation measures in Dows I'm seeing are trying to get at. But they're not really measures and they don't get at what the science recommends. So capability, can the person do what they're promising? I'm not going to trust them if they don't have the skills, the integrity, are they conscientious? Are they going to keep their word? They might have all the skills in the world, but if they're Bernie Maddoff or Sam Bankman Fried, I'm not maybe not going to trust them too much. Or if they have skills and they're highly ethical and high integrity and conscientious, benevolence is the last one. Do they have the value system and care enough about my Dao to point their tremendous skills and conscientiousness in the direction that the Dao needs them to? So these are all sources of variation that are very measurable. You can see a citation at the bottom, a meta analysis in one of the top journals in organizational psychology. One of the things I'm hoping to leave you today with is a better appreciation for whether it's the interdisciplinary science that's required in Dows to derisk them. It's this persuasion stuff focused on, say, the bottlenecks, these constraints I alluded to before. We need to be able to trust the measurements to test our scientific theories, but also to make good decisions in Dows. And most of the social science measurement are not useful. They're not trustworthy in the way that we would want them, that we're used to in thermometers and rulers. The only technique in all of social science that metrologists these are specialists in science that specialize in physical measurement, including measuring time on our watches or thermometers chemistry biology. It's the only technique. The Roche Measurement family of techniques basically approach quantitatively how to think about social science measurement in the same way that they already always did with picking mercury for the early thermometers and then realizing mercury was no good, measuring super cold things because mercury freezes. And that's when they created the Kelvin scale. So this kind of approach, Roche Measurement is the only one that really can serve these purposes. Whether it's measuring Dow customers, whether it's measuring Dow members, the culture and the community of members, it's the only one that has the same properties as our friends in physical, chemical, biological science. So just to give you appreciation for what this does, it basically says people. Since I'm a psychologist, I think mostly about people. But it doesn't have to be people. It can be any object or thing. It basically puts people or things or Dows on lines to make sense of them. But it's really measuring one thing at a time, and it has special properties. It's not just data. Data can be lumpy. It can be unrepresentative. It can be too uncertain to use. And my big concern with when I see Dow measurements today is they don't take the care to report how much bias they have, how much error they have. In most studies in psychometrics, the kind of diversity bias is sometimes there, but it's typically small if it's there at all and you can remove it. The part that's large is typically severity and leniency bias. So we can all relate to when we were kids and we were in school, we had teachers that were tough graders, we had teachers that were lenient graders. That severity, leniency bias is super impossible to compare and make these reputational measures in Dao useful unless you use these quality control techniques called Roche Measurement. Measures are concatenatable. They're linear. They only measure one thing. Two and two equals four. And these new techniques in social science, when built correctly, can give us the same level of information without these biases, without these severity and lensy bias that's trustworthy and comparable over time. And in Dow risk management or in Dow science, that is crucial to being able to test our theories about Dows as well as manage Dows and see if the levers I'm pulling are actually making a difference in a credible way. Too many of the traditional social science measures have so much noise, especially in the high and low ends, that you just can't make sense of it. The newer computer adaptive tools, like the one I mentioned with Bob Cialdini can get us there. And the kind I'm working on now are more artificially intelligent variety that use the large language models. Well, how do we do that? How do we make these? Before we talk, I'm not going to get too deep into the quantitative side, but how do we conceptually do this and making sure we know why this measure works, whether it's AI or traditional, and make sure it's useful for pulling levers and mitigating risks or testing theory? Well, here's an example. I've worked for many years standing in the shoulders of my friend John Antonakis. He's a professor at University of Lausanne in Switzerland who studied how to measure and teach charisma. So if you're a Dao leader and you want to inspire people to join your dow, there's incredible science that it's measurable, it's teachable, and it's very economically powerful with excellent real world experiments that he has pioneered. And he's the editor of Leadership Quarterly. To create these measures, we need to know ahead of time what's super low look like. Like a Kelvin zero. Well, in charisma, simply talking about the importance of the team's work is pretty easy. The ethics of it, that is very easy. You don't have to do anything fancy. But it's important to start at the lowest levels of charisma, at the highest levels, using incredible metaphors, non verbal behaviors, modulating your voice, colorfully describing your vision. These are the most difficult kinds of items. And asking people around you, do they experience your behavior as inspirational in these different ways, predicts many things, including economic outcomes. In professor Antonakis'studies Roche basically gives us a way to say, do these questions behave like I would want in a ruler? And make sure that you've got good information. In a coaching or training environment, if a Dao founder is lower than they want, there's coaching. You can give them the things that they've mastered that are too easy for them, things that are too hard versus tasks they should work on to become more inspirational and more effective. As a leader of the Dao, there are other examples I can give too, just briefly. This is another instrument that I created with the International Coaching Federation. Some of you may be surprised to know in all the studies of people at work pre Dao, they're almost all people's. Job performance is not normally distributed. It's almost all skewed. It's in a power law distribution. So there's a lot of data kind of at the lower end and then a fat tail very skewed on the right, and you can see it's kind of pivoted on the left side. ACC are the lowest level junior certified coaches. In the International Coaching Federation. MCC stands for Master Certified Coach. And what I did with them, their scientists and their senior, most coaches is say, all right, well, what's the science say about what long after coaching is over? We want to know if coaching is working, if it's impacting the organization or the person, if it doesn't achieve its goals or people get worse, that's no good. So at the bottom of the scale, we wrote a bunch of questions that clients of coaches get asked three months, six months after coaching is over and saying, did this last? Was it worth it? If it wasn't worth it, obviously that's no good. And if they got a little bit of gains or they got all their goals achieved, that's a good gain. Sometimes at the top of the scale, people leave a single coaching engagement. This is rare, but it happens. They say, this changed my life, my life trajectory. So you can see where we've conceptualized this part of organizational science. This is performance of a coach long after coaching is over from the point of view of the client who consumed the coaching. And we have a computer adaptive Roche measurement approach to measuring these things. And we see this sort of power law distribution when we create these measures. So obviously in organizational science or in mitigating risks of Dows, if I'm trying to improve something, I want to see if these things are shifting up. And I want small amount of error in my measurements to say, was this significantly better than last time? Is the team or the person getting better? This is the only kind of quantitative picture I'm going to show you. But what's unique about Roche as opposed to the other social science methods in psychometrics? The reason this is appreciated by Metrologists is because it separates quantitatively and objectively measures of the person in the Dao, measures of the questions being asked, or the AI being used to measure the person in the Dow from the rating scale. And it removes the different kinds of biases I just described. So it's truly objective on one scale in some dimensions that are relevant to DAOs, like conscientiousness reputation approaches to conscientiousness are two to three times more predictive of workplace behavior than self report. When just asking somebody if they're going to keep their word types of stuff, not all things are appropriate for that. But this is what makes Roche special. But at the same time, even though I'm convinced persuasion is highly relevant to DAOs, it's not obvious. Am I right? I could be wrong that persuasion is I think it's more important in DAOs than it is in a traditional organization. But I might be wrong. There are many phenomena in DAOs that seem more fluid than a traditional organization. And the fact that there's so many joint projects across DAOs makes me think maybe there's something about cross functional teams, which is a very bleeding edge of organizational science, we just don't know that's really worthy of study in Rndao. There are many aspects that DAOs have not always been robust to risks. How do we make them more antifragile? It's not obvious how to do it. So I think it's a very rich area to study. I would submit to you that thinking about those constraints, those bottlenecks to the ultimate Dow risks, are perhaps the best way to focus where to start. But to do that, to test good hypotheses in any science, including Dows, we need good instruments. And that's where I'm advocating, and I'm passionate about creating on chain, immutable permissionless, smart contracts that preserve privacy and anonymity for Dao members, but give DAOs visibility to these risks in a way they already do to some degree with smart contract creation or fiduciary tokenomic kinds of risks. We just don't have that same level of sophistication on the human team and organizational side as we do on the engineering and finance side. So, so far in this talk, I started with kind of the big picture. What was the purpose of crypto to begin with in the early Bitcoin era? How did it evolve? What were the risks that are still present, that were present before Satoshi, I talked a bit about why we should think in an interdisciplinary way about there's so much exciting potential for DAOs, so much we don't know. Organizational science pre crypto, pre DAOs was a lot less mature of a science than, say, physics or chemistry. And Dows add new variables, new exciting things that we just don't know. To really test those hypotheses, I tried to make the case for you. We need good measurements, and there's a family of those in social science that are a good interdisciplinary way to build bridges with our friends in software engineering in the finance world because they meet the same requirements as any other science. These are these Roche methods. I hinted at computer adaptive tests. These are computer adaptive assessments. Those are obtrusive where you basically get questions asked and they're kind of a pain in the ass. The more exciting kind, the kind I'm working on right now, are totally unobtrusive with the large language models you can basically query. And there's early science with GPT-3 before Chat GPT even came out, that you can get good unobtrusive measurements just from what people are saying in a Dow, just from their behavior in discord. Obviously there's privacy concerns with this, but there's tremendous potential to get good Dow information, maintaining privacy with some of these newer AI things if they're on chain, if they're dealt with in an ethical way. And so I'm convinced that and I won't delve into my vision for some of the engineering pieces. And I'm sure some of the people on this call will be smarter than I am on the engineering side because I'm an interdisciplinary psychologist who's dealt with web one, two and three to a limited degree. Web three tech for a bunch of years. But I'm not an expert on the software side. What I'm envisioning to make the science go better and the enterprise risk better is a kind of not only assessment smart contract with UIUX layer and some of these adaptive algorithms both the kind where you have to ask people questions and this unobtrusive large language model AI kind I'm talking about, but also either a new kind of psychometric non fungible token with multi key sigs or some new kind of secure storage smart contract kind of storage where human team and organizational dow data can be stored for both science purposes and management purposes. You can see where if that's done in a multi key wallet where the anonymity is preserved, it could potentially really help organizational science as well as the Dow leaders to say, what does this all mean? And if that sort of stuff is worked with good science about what individuals and teams science are supposed to be fed into dashboards, that mitigate risk. It pretends a renaissance in both the science and the management side of this. As long as those reports are immutable, they're permissionless, they're aggregatable. And you can summarize what it means in the same way that engineers in Six Sigma would look at statistical process control charts or data over time and look at if we do these certain things, is it producing a measurable gain in reducing the human team or organizational risk alongside the engineering and financial risks? So I hope to leave you and Daniel warned me that he may have to go. So I'm happy to take questions here or clarify things if you like, but I'm here to make the case that to mitigate risks in DAOs, to realize the full potential of DAOs, we need better science. To manage to lead Dows, we need better tool sets. Some of those are including measures I'm making the case for on chain transparent immutable psychometrics that can be trusted for both the science and the management. And if they're done right, transparently immutable composable decentralized. It can be a real renaissance for Dows, making the kind of transformational impact I think many of us feel that they can have. So let me stop there. Daniel, I know you have to go here in a moment. I was focused on my presentation, not on the chats, but so there were any things I should.
[ 0:38:56.000 ---> 0:39:36.000 ] Speaker A : This is you have gone over so much, I feel I've been drinking off a firehose. So thank you for that, actually. I really appreciate it and really enjoy it. Yeah. Unfortunately, as mentioned, I got this other talk double booked, annoyingly, so I won't be able to stay for the full discussion. But thank you very much, Matt. I'll definitely reach out to you in the chat because I see some very interesting potential on this. And then we just need to start bringing it down to the super concrete use cases. So we can pitch it and see how to evolve applications, but love the vision. Thank you so much for the overview. Look forward to continue the discussion.
[ 0:39:37.000 ---> 0:40:06.000 ] Speaker B : Muchas gracias. Thanks for inviting me. Thank you, Wendy. So I've got the chat open if people would like me to talk about something in more detail or if I was unclear or challenge me if you disagree with something I said, I'd be delighted to give you my take. I could be wrong, but I'll give you my take on why I thought some of those arguments were compelling. Yeah, Matt.
[ 0:40:07.000 ---> 0:40:17.000 ] Speaker C : Well, I'll just jump in and leave a few comments. I don't necessarily have any particular questions other than just a desire to continue working with you and seeing what you guys are developing. And it's very exciting.
[ 0:40:17.000 ---> 0:40:18.000 ] Speaker B : Thank you.
[ 0:40:18.000 ---> 0:40:49.000 ] Speaker C : The idea around contributor reputation. And building that trust is a huge component of what I'm focused on right now for my projects because I see that as being one of the most essential steps for us to be able to move forward with this idea of decentralized governance and permissionless contributions. There needs to be some layer that establishes the equivalency of what real world trust is established on. Much like you were talking about. So I think this really powerful stuff.
[ 0:40:49.000 ---> 0:41:00.000 ] Speaker B : Nice. Can I just ask you what makes that trust super tricky right now with your current tool sets? Really?
[ 0:41:00.000 ---> 0:41:36.000 ] Speaker C : It has to do with the desire and the need for pseudo anonymity, whatever that word is we all know. And that it's hard to establish trust when you don't know if somebody is just LARPing in that role, if they're live action role playing, or if they're genuine. And also you don't really know anything about where they're coming from in life. Sometimes people's life circumstances change and that changes their commitment to the project.
[ 0:41:36.000 ---> 0:41:36.000 ] Speaker B : True.
[ 0:41:36.000 ---> 0:41:59.000 ] Speaker C : There's no way to really establish that because we're trying to give people the ability to come in and leave permissionlessly. So there's no job description, there's no contract, there's no commitment there's just bring what you have to the table. If other people like it, they'll support it, and if they don't, they won't. But if you abandon that halfway through, then it's now a leaderless project that's going nowhere.
[ 0:41:59.000 ---> 0:42:33.000 ] Speaker B : Sure. Yeah. There's a lot that the Persuasion science has to say about how do you get them to make a commitment. There's a lot we could do to detail the risks, some of it's over time. Historically in social science, we don't do a good job of time series types of measures. Right. But that's part of that trust. If they're going to remain anonymous, crypto, trigs, we'd like to know, are they consistently keeping their word about deliverables to the project? Do they have the skills that are required? Are they maintaining conscientious? Or did that drop off over time on chain stuff that collects itself automatically? Gets us a step in that direction?
[ 0:42:33.000 ---> 0:42:40.000 ] Speaker C : Yeah, exactly. And by the way, you can just call me Triggs. The crypto is a silent okay, thanks.
[ 0:42:41.000 ---> 0:42:47.000 ] Speaker B : And you had something else there too, Triggs. I didn't mean to interrupt you. I just wanted to ask about the yeah, for sure.
[ 0:42:47.000 ---> 0:43:34.000 ] Speaker C : Well, you touched on it a little bit, too with the verifiable skill set. I think that's another huge component because with the ease of contributors to jump in, it's kind of like I feel like crypto is in this space right now where ideas are everywhere. There are dime a dozen. Everyone's got great ideas, and ideas don't really do anyone any good if no one's really willing to do the work or capable of doing the work. And we have no way of verifying someone's skill set without taking away that anonymity. And so with established on chain reputation, over time, people can build that resume that on chain resume that demonstrates their skill set, and that'll go a long way towards establishing trust that, oh, this person follows through because look what they've done in the past.
[ 0:43:34.000 ---> 0:43:34.000 ] Speaker B : Sure.
[ 0:43:34.000 ---> 0:44:19.000 ] Speaker C : And I think the other side of that coin also is that people who are high quality contributors are hesitant to get involved in Dows because they don't have assurances that what they're working towards is what they think it is, or that they're going to get recognized or compensated for that. I've spent the last year pouring my life into a couple of projects, but I have no on chain record of that whatsoever, and so I have no way to justify any sort of compensation for that or when I go out into another job, there's no way to verify that I actually did those things. I think that's a huge barrier for a lot of high quality contributors to get into the Web three space because they have no security that their work will actually go somewhere.
[ 0:44:20.000 ---> 0:47:35.000 ] Speaker B : Excellent points. No, I think about five years ago, a company called Velocity Network Foundation was created to address some of those things. The problem with them is they predate the idea of a layer two. They didn't go down the ethereum or any kind of ecosystem path. They built their own private blockchain. And it's all permission, KYC. It's not going to work in the Dao world. Even though they had good smart contracts, they have a lot of the kind of psychometric NFT type stuff, I think, that I've been envisioning. But it will never work for some of these anonymous use cases you're talking about. And it's fragile. Right. We've seen again so many times in crypto that centralization destroys organizations. And so what happens if Velocity Network Foundation's stakeholders all turn off the blockchain? That can't happen on ethereum, right? It can't happen in any of the layer two type stuff. So I think we do have near term solutions, straightforward science that can help mitigate the risks of those. But it's not obvious to me what the right software architecture is. We're not yet in a cross layer two world. So inevitably you build something on polygon and somebody else is an arbitram or optimism. There's not a great way to integrate some of that stuff unless it's like a psychometric NFT type thing. What's the taxonomy for it? I think better than a resume. Triggs. What I'm envisioning is anybody that wants to look at the detail of where that damn measurement came from or what smart contract generated the code and whether it's timely the dates. Even if the person's anonymous. Maybe it's out of date. And I don't know, maybe there's something new to learn now that wasn't around the last time they get measured. Resumes have none of that. Triggs right. What I'm envisioning is a much more trustworthy set of information. But to do that, you got to have a Dow that's got the wherewithal to actually care about making this thing meaningful. Right now the reputation measures don't look like measures at all to me. I don't see how they're maybe I hope they're useful, but I'd be surprised. There's not much you can do with it because you don't really know what the variation is from in those measures. Is it because you had hard asses rating you? Was it timely? Is somebody using three smart wallets so you get the same identity problem as you do elsewhere in crypto? But what's nice about this is if you've standardized on whatever the identity wallet is, you've got a way to empower the individual to turn a smart key and only release what's job relevant or task relevant to that Dow and not their whole profile if they don't want to. But the Dow gets some way to know, is this all working the way it's supposed to before I give a grant? Is this person likely to do right by it because they've got the skills, they've got the integrity and their values are matched up with what we want. There are good ways to do this, but there's some important work to happen. And if we step back from the engineering and management details, I would submit that infrastructure is required to test so many organizational hypotheses about how to make Dows better from a pure science point of view, too. Is that my answer resonate with you, Triggs, of how I'm thinking of it?
[ 0:47:35.000 ---> 0:49:10.000 ] Speaker C : Yeah, absolutely. Mirrors totally what I've been thinking. I really appreciate your perspective because I feel like you're coming at it from the organizational science perspective that's really lacking in the web three space. I've seen this so many times with people like yourself who are industry experts that have been doing this for years. And you come into the web three space and recognize how it's like all these little kids running around repeating all the same mistakes that we learned the lessons already for the last 100 years or 100 plus years, and yet we're just reinventing the wheel with all this stuff from scratch, and we don't need to do that. Right. And another aspect of what you're talking about that I think is huge, and you mentioned it right here in your conclusion. It's the composable, the immutable composable measures. And I think there are a lot of groups right now because I've been pretty much focused on this for the last year. So I've been kind of tracking groups that are working on building this composable data set. And so something we can talk about in the future. I would love to kind of get your opinion on some of these projects and what they're building, but the takeaway that I've gotten from the research that I've done so far is that all of these groups don't really know how to build what you're talking about. They just know we need the data. And so that's what everybody's trying to build right now is a way to collect composable data so that once we start getting the metrics defined and all of this stuff kind of organized, now all of a sudden, we have a massive data set from the last year's worth of collections that we can just start running through this filter and producing those sort of specific use case applications that you're talking about.
[ 0:49:10.000 ---> 0:51:59.000 ] Speaker B : Well said. Yeah. I mean, let's just use one kind of concrete example of why this is so important. Like, think of back. Vitalan was a bitcoiner wrote the Bitcoin magazine. He was a genius back then before he got funded by Peter Thiel. And he's probably better at thinking about Solidity and Blockchains today than he was at the beginning when he first dreamt up the ideas, right? And so he's now much more of in the persuasion space than he is in the Solidity programming space. But he's just as conscientious and just as intelligent as he was at the very beginning. Right. And so that immutable measures of vitalik on conscientiousness and cognitive ability would be repeated measures won't change much. He's just as smart and high integrity as he ever was, but he's probably way better as a persuader, way better as a charismatic speaker. If any of you saw his talk last week at DSI in London, amazing, inspirational, very big picture, very humanity level kind of stuff. And I think he's better today at that than he was earlier. And wouldn't it be nice in Dao risk management if part of our Dao wants to look after the ongoing development of senior leaders like Vitalik is to say, all right, some of that stuff across chain, I might want to know if a given person who's not famous like Vitalik is smart and conscientious, that won't change much. But what will is their skills. Maybe Solidity is no longer the programming language in ten years. Maybe it's something else. And does this person have potential to go learn that if Solidity is not the language, if we're talking community and treasury, it's similar. I'm sure tokenomic models are going to evolve too. And there's skills around designing those that are fair and equitable and useful. And what are the antecedents? Well, the individual variables are some team variables that I mentioned, right? The teams that are creating the financial treasury risk that you're talking about, Triggs, are they effective? Do they have psychological safety? Do they have good coordination? Do they collectively, what is the aggregate distribution of their persuasion? If they want to go build relationships, like Rndao has some relationship with Talentdao or the Lab Dao, talent Dao and Labdao have a joint Project Lion. There's some relationship persuasion skills that individuals and DAOs or collectives and DAOs need if they're going to do cross chain collaborations. Like all of those are sources of risk that at the governance level need to be similarly concerned or sophisticated as what already exists in finance and engineering. Let's see. Let me ask maybe just one or two more questions and I will call it a day. Are other folks other than Trigs have a question, something you want me to clarify or an observation you can either put in the chat or feel free to just turn your mic on.
[ 0:52:02.000 ---> 0:52:27.000 ] Speaker D : I just want to say I joined really late. I had another meeting. But just hearing you guys talk, I think this is such a cool topic and it's been something matt, I know we've met before, but I psychologist as well, and I've been interested in a lot of the kind of crypto and blockchain side of things for a couple of years now. So seeing that come together is really cool and I'm looking forward to listening to this entire talk once we get the recording.
[ 0:52:29.000 ---> 0:52:32.000 ] Speaker B : Excellent. Namaste. Kataki, thanks for joining.
[ 0:52:32.000 ---> 0:52:32.000 ] Speaker D : Yeah.
[ 0:52:36.000 ---> 0:53:06.000 ] Speaker B : I think there's tremendous so Kotaki, I don't know if you know about Talent Dao. It's a bunch of iOS who created a Dao and they're creating a journal of decentralized work. But that's the Project Lion I was just referencing where there's an IO working with a machine learning expert at Labdao to create on chain social network analysis. So you could see where some of this is already starting, but it's really just scratching the surface of what's possible, if that makes sense. Does some of that resonate with you, Kotaki?
[ 0:53:06.000 ---> 0:53:50.000 ] Speaker D : Yeah, absolutely. I'm on the email list for the Talent Dow, so I get updates every now and then. I think that's really cool. And one of my friends who's also an ORC psychologist but now is the CHRO first malt web three company we've been working on just kind of what are some ways in which we can help business leaders within a more traditional Web Two framework. I'm at Microsoft right now. How do we help them think about the future of all of this? And I would love to kind of continue this conversation and keep thinking about this because I think DAOs are where our mind immediately went to just like this new way of working together.
[ 0:53:50.000 ---> 0:55:50.000 ] Speaker B : Yeah, no, I love that Kadaki I'm happy you mentioned Microsoft because I think what's extremely exciting for science and this risk management right now for me personally is just the breathtaking work. Microsoft just invested a huge relationship with OpenAI and these new large language models that Microsoft's integrating are such game changers. And so some of my vision for the Dow world and Web Three is to also have hooks into Web Two in things like Microsoft Azure because already there are publications showing that GPT-3, that's a precursor to Chat GPT, can, can emulate human personality. And so instead of automatic item generation I talked about before, automatic raider generation is what I'm doing now where you can basically have prompts in a construct map like I showed before, like Charisma or any of those construct maps. But on chain you'd want to make API calls to the best AI. So some of it's on chain through algae Verna, but that's too bleeding edge. It doesn't have the latest algorithms the way Microsoft does. So you can see where I think part of our vision needs to be a bridge between Web Two and this advanced Microsoft stuff that's going to be I mean it sounds like Microsoft's building Chat GPT into every product soon like in this year. But meanwhile API calls for real time unobtrusive psychometrics is like a complete game changer for I O, right? Both the science coaching right, where you don't have pain in the ass items anymore, but you got meaningful measures and you can imagine what that's going to do for Dows. And I'm thrilled that Microsoft's taking the leadership role in investing in those things. I'd love to see that stuff go on chain though, so it's more organic over time and we make the full transition. But realistically we probably have a transition period between Web two stuff like Azure and on chain stuff going forward. Does that resonate with you?
[ 0:55:50.000 ---> 0:56:48.000 ] Speaker D : Kotaki yeah, absolutely. And I think I've heard several folks now say for the lay audience to get from Web Two to Web Three we're definitely going to need like a Web 2.5 where Web Three has to make people's lives easier in some ways to get them to participate. And especially with the current crypto ecosystem, the cynicism is so high that it's actually really interesting when I talk to some of my colleagues or friends that are not at all related to this. The kinds of things that I hear really go to show how right now the more public kind of impression of Web Three is just this wild, wild west where everyone's just trying to make a quick buck but there's so much below the surface when it comes to the technology itself and what that can do. I think that education gap or knowledge gap is one that we need to start with before we can get kind of that mass adoption of some of these concepts.
[ 0:56:48.000 ---> 0:57:53.000 ] Speaker B : Yeah, well said. And let me just point out as we close because we're a little bit over our time. It's not just the for profit side, right? Klimadao has been around for more than a year, right, on climate change and buying carbon credits. There's this new DSI work with Arundao and talentao. The lab like these are all scientific endeavors that are more they have a more not for profit flavor to them, at least right now. So I think these are universals for organizations. They can be in the for profit world. They don't have to be. But all of them need immutability. All of them need transparency. All of them need to be uncorruptible on chain. And that's where I'm excited about taking this work. So with that, thank you so much for joining. And if you want to connect with me, I'm at Matt at excellency. I thought I had a slide with my email on it. It's Matt at Excellency XLNC Co. And if anyone is interested in collaborating with me on these, I'd love to talk. Again, thanks for joining. Have a great day.
