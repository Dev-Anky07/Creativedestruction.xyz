[ 0:00:08.000 ---> 0:10:51.000 ] Speaker A : So I'm going to take a quick minute to tell you just a little bit about myself since we all just did these intros. I am, let's say, tech fluent. I'm not a I'm not a tech developer, but I've been coding. I first learned Q Basic in 1995, so I've sort of been Dabbling ever since then. Some fluent, but not much of a practitioner. I used some code to develop online experiments. Then I went to university. I studied philosophy of science. That has a huge impact on how I think about the world. I then worked for a while as a practitioner, as a mediator. So that's working in facilitation and conflict resolution, really focusing on thinking about how groups can make decisions. So not just conflict resolution, but things like, what should we do next? And then I worked for a little while in customer service, which is also about communication. And then I did a PhD in communication. So you can weave a narrative here, although it's mostly just very random wandering through life. I then did a postdoc at the Kellogg School of Management, and then I moved to London to become an Assistant Professor of management, which is what I'm doing now. And I just continue to think a lot both about the philosophy of science as well as about communication. So you're seeing just the slide, right? How do you yes. Okay, cool. So what I'm going to talk about today is how collective decisions happen. I'm not going to answer that question, and I'm not going to tell you how to optimize collective decisions. I have a lot of thoughts about that. But we have a fairly short time period today. So what I'm going to try to do is just give you a sketch of how I think about things. I'm going to focus on three different types of collective decisions, or at least three different processes. They're all going to be related in many ways. There's not necessarily a clean decision or a clean distinction, but this hopefully, will give you just a little bit of a framework for how we think about it. And I am more than happy to follow up with further in depth conversations if anybody's interested in diving into this more. I love talking about this stuff, and I particularly love hearing about people's practical problems. Although I'm now an academic, I try to keep a very solid foot in the world of practice. I'm currently consulting with an organization who's trying to harness collective intelligence to boost innovation in their company, which is really exciting. I'm working with a couple of folks here to develop an AI Bot to facilitate group decision making, and those kinds of things really help me think about what are the scientific and theoretical problems that we should be studying. So I'm particularly interested in this question of how do collective decisions happen? And then examples of things I'm interested in. I'm interested in things like policy generation I'm particularly interested in wicked problems, things that are really technically difficult, but also have to satisfy competing stakeholders with various needs and interests. So things like development of climate policy or designing a sustainable health care system, right? These are simultaneously technical challenges, but also things where you have to deal with people who simply have different priorities. I'm also interested in organizational strategies and I use the word organization very loosely. So something like a dow? Well, the O is of course, for organization, right? So organizational strategy, whether it's a top down hierarchical firm or something like a Dow, I'm interested in how they make decisions with, of course, an interest in optimizing how they make decisions. Things like land use development. Right. Here's a big empty plot of land. What should we build here? I once did a mediation that was focused around that for an empty corner lot in Baltimore. Right. It's not all about conflict resolution. All right, so I'm going to talk about this in a few different ways. The very long version and in person version of this involves people actually doing some experiential learning activities. We're not going to do those today, but I'm going to tell you what they would be just to kind of anchor you. So the first activity I would give you is I would kind of randomly assign you into a groups of just three or four or five people and I would make you agree on a budget. Something like you have 100 monero so random money units and you have to move into a new flat. And you can assign some of your budget to location, some of your budget to amenities, some of your budget to the number of bedrooms. Right? All different things that you prioritize in various ways for choosing a flat and things you might not all agree on. And I'd ask you to agree on a budget. So this is like that land use development deal. So I'm going to talk briefly about a case study that I've been analyzing lately. This is developed by the Dispute Resolution Research Center at the Kellogg School of Management. That's where I did my postdoc and I'm collaborating with them. I'm also going to share some things, ideas from John Atwell at Stanford. So credit where credits do. So this is a case study we give to our MBA students to actually negotiate when we teach negotiations. So you've got six parties trying to decide what to do with a plot of land. You've got the actual developer who's going to fund and build the project. You've got the mayor, got the City Planning Commission, a green environmental interest group, a residents interest group, and a rival developer. And they're all at the table. And you have to get at least five out of six have to vote yes on whatever the deal is. And there are five different issues. Issues like how much of this will be residential versus commercial. So property mix, how much of it will be low income housing? How much will we devote to green space? What's the max building height? What's the number of entertainment venues? So this is just a classic kind of multiparty, multi issue negotiation. Just like that mediation I once did, or just like you all might be working out if you're trying to decide on a budget, right, with a bunch of different issues and a bunch of different people. Okay, and now I'm going to get into why I'm particularly interested in this case study. I'm going to walk you through my thought process here. We can actually take this case study and we can take all the different possible outcomes. 30% residential, 50% residential, 70% residential. And for each party, the developer, the mayor of the city Planning Commission, we can assign them points like how much do they like these various issues? Okay, so we can now map the entire negotiation. This is the actual payoff structure that we give to students when they're completing the simulation. You don't have to read the details here. This is just sort of to illustrate that you can capture this entire negotiation with this matrix of numbers right here. So the columns represent the different parties. Stellar Cove is the developer. Green Living Collective is the environmental group. There's the mayor, the residential group. The columns represent parties. So the rows represent the different issues property mix, low income, residential, green space. And then within those rows, each of the subros represent the different possible outcomes. And then for each person, we assign points. So the upshot of this is that if I am trying to make a proposal in this negotiation, I don't have to go into all the details. I can just index each of the rows and each of the solutions. So I can give you a solution. Something like lost a slide here. Something like 13452. Right? That would be the first option for property mix, the second option for residential, the third option for green space. Whatever the numbers I just said going down. And you can calculate the payoff, and the Ilium group can calculate the payoff. And then everybody can take from this vector of numbers, they can assign that vector of numbers to a payoff. And I, with my God's eye or bird's eye view, can take a vector of numbers and determine how many people will vote yes or what the joint payoff is. So this is a way of saying I can take a vector and map it to a payoff in this complex land use negotiation. So that's where I'm getting at so far a way of thinking about proposals in this negotiation. Oh, yes, that reminds me. Thank you, Sylvio. Please feel free to interrupt the question throughout. It's totally fine if I don't end up getting through everything. So Sylvio, go ahead. Super interesting. My question rises from how do you quantify the decision tree to create the vector from and then how do you export that into a vector store to extrapolate the insights? Well, I'm not quite sure I understand your question, but the vector in this case would be defined. So each entry of the vector I'm going to put something in the chat here just as an example. How do I get my chat back here? Here's an example of a proposal as a vector. So there's a proposal as a vector, the index. So the entry five entry vector, the index refers to the rows. So the first entry refers to property mix. The second entry refers to low income residential. The third entry refers to green space and then the value refers to the item order. So the number one for the first entry would be a 30 70 mix. Number three for the second entry would be 12% residential. Number two for green space would be 16 acres. So that vector is referring to a set of solutions on this payoff chart here. And then you just add up the payoff based on that chart to get the payoff for an individual and you add up the payoff for everybody to get the total joint payoff. Or you can consult each person has like a bottom line, they won't accept something worth lower than that point. So it's called the reservation price. You could also use that to calculate how many people will vote yes. We're assuming everybody's perfectly rational and voting yes on anything that would satisfy their bottom line, their reservation price. Okay, yeah. Now the thing about this negotiation is it's very difficult. I would say about half of my groups never reach agreement. So we can see this negotiation as a what's, I'm sorry, Nelson, what's? The bold assumption?
[ 0:10:53.000 ---> 0:11:17.000 ] Speaker B : No, the assumption that people would make rational. Yes, that's a huge assumption decision because very often the human parameter enters into the context. So like, okay, if it's your proposal but then I have an issue with you that might be personal or at work or at something else, then that kind of like muddies the water a little bit.
[ 0:11:18.000 ---> 0:21:23.000 ] Speaker A : That's a great point. First of all, I'm going to question some of these assumptions. This is an ongoing project. One of the first things we're doing is just testing this. Also one of the nice things about this framework is it allows you to convert subjective preferences emotional, how much do I like you? Maybe I just really like tall buildings. There's no dollar sign payoff. It allows you to convert subjective preferences into quantifiable payoffs because these numbers can be anything. So we also teach creating a point system for a job interview where the points refer not only to the salary, but to how much you like the city, is your boss nice to you, stuff like that. So we can convert all of those subjective preferences as well into this. And then you can also relax some of the assumptions maybe people make mistakes. Maybe they're lying, right? There's all sorts of messy stuff people do. But whatever your assumptions are about how people vote, you can always represent a proposal as this vector. So this particular negotiation is very hard. So we can see it as a challenge for the group, right. How does the group find the solution that everybody will say yes on? So I'm just going to briefly show you again, you don't have to take in all the numbers on this next chart. This is a list of all the possible solutions that would actually get a yes vote. So there's only like twelve solutions on this list and I really should calculate this out. But if you take the combinatorics five times, three times two times four times two, whatever it is, if you take the combinatorics, there's thousands of possible solutions, but only twelve or 13 or whatever the rows here is, that would actually be a viable solution. So how does this group find out of the thousands of possible solutions, the one that will actually satisfy them? And for various technical reasons, the way this is run in class, it's often actually only the top row that people will vote yes on. So there may even be, depending on how people interpret their role materials, there may even be only one possible solution that the group will get vote yes on. So how do they do it? That's my theoretical question. That's my theoretical question. How does multi party, multi issue negotiation happen? Okay, so I'm going to give you a proposed behavioral model that is a very strict one. So for this first one, Nelson, you're going to find it maybe a little bit of bold assumptions, but there's a lot of relaxation we can do. I'm not going to get into all the messy details and I'm going to acknowledge this is the work in progress, but this is just a way of thinking about it for now. So my behavioral model builds in the assumption that people, when they make a proposal, it's like this vector 11352. So here's my behavioral model for how people negotiate. And there's a lot of assumptions here. This is just a way in. This is a start because what we do as scientists is we come up with models to explain phenomena. So a randomly selected participant starts the negotiation by offering a proposal. So Nelson jumps in and says 12352 and I take that proposal, I make a slight modification and I offer a new proposal with that slight modification. So this is myopic search. This is a common psychological tendency. People are anchored on whatever was said before. So I'm not going to just pull up a totally new proposal out of the blue. That is an assumption, by the way. But my next proposal will be very similar to the previous proposal and we'll just keep repeating that until an agreement is reached or until we run out of time. And between these stages, there's some kind of discussion that happens. So that's a really specific model. That's something that we're going to be trying to empirically validate soon. But there's a much more general model. At some point in the negotiation, someone is going to offer a proposal and that proposal will either be accepted by everybody or not. And if that first proposal fails, at some point in the negotiation, someone will offer another proposal. And if that fails, at some point someone will offer another proposal. So whether you accept all the specifics about people's cognitive styles and anchoring and the tendency to make only slight little changes, we can characterize a negotiation as a sequence of proposals. And you're following that sequence of proposals until you run out of time or until agreement is reached. So I'm going to make a big leap. Now imagine that you're taking each of these proposals and you're quantifying them by some objective function. Let's just say the number of people who vote yes, right? We're trying to maximize the number of people who vote yes. As I am taking this proposal and just modifying little bits at a time. Nelson says 11352. I say, okay, what about 11353? Nelson says, what about 21353? We're each making slight little modifications. As we make these slight little modifications, maybe more people are voting yes, maybe less people are voting yes. We can visually or conceptually represent this as navigating a literal landscape as you're tweaking it. You're either walking up a hill as your proposal is getting more and more yes votes, or you're walking down a hill as the proposal is getting fewer and fewer yes votes. I'm going to throw out one more assumption. My assumption is if I make a modification and it's worse, we're not going to keep it. We're going to go back to the better one. Now I have analyzed this particular case study, and what I can tell you theoretically is that if people follow this process of making a sequence of proposals and they only keep the proposals that are better, they can get stuck on what's called a local peak. So imagine you're wandering the mountains and your goal is to get as high as you can, as close to the sky as you can, and you only ever go up. And the first place you get is this point labeled A. You can no longer get anywhere higher just by going up. Or in the case of the negotiation, you can no longer get anything better by making slight modifications. What you want to get to is point B. That's the best possible outcome. But the only way to get to point B is by tearing up everything and going somewhere completely radical. And my supposition right now is that negotiating groups rarely or never do this. So this is the search model of negotiation. It's a framework I'm developing and it has a fairly substantial implication because we can now categorize negotiations by two features. The first feature is called the zone of possible agreement. And you can just say count the number of feasible solutions. So if there's only one possible solution people will say yes to, that's a small zone of possible agreement. If there's a large number of possible solutions, that's a large zone of possible agreement. So we can characterize negotiations based on the Zopa, we can also characterize negotiations based on the complexity. So this visual representation here is a complex landscape. It's possible to get stuck on local optima. You could also imagine maybe just the center of this. No matter where you go, if you go up you're eventually going to reach the peak. That's what I would call a simple landscape. So here's our hypothesis that we have yet to test. So this is a work in progress. I'm telling you about classic negotiation theory would say that the smaller Zopa makes for a more difficult negotiation. This collective intelligence based search model means that more complexity means a more difficult negotiation. So my hypothesis is that if you have a negotiation with a small Zopa that's very simple, that will in fact be easier, which is to say more likely to reach agreement than a negotiation with a large Zopa. So a lot of satisfactory solutions but a lot of complexity because it's easy to get stuck in the complex negotiation and never find that better option. So that's a hypothesis we're going to test. I said I had a theoretical question of how multi party, multi interest issue negotiation happens. I also have an empirical question. This is to get to Nelson's point, we have to start testing these assumptions. So this is something we're going to be doing next month. We're going to be recording video of people completing this negotiation. We're going to code their behaviors. So we're going to take the text of their actual discussion. We're going to try know, boil that down to some basic elements like a proposal offer, right? We're going to try to generate a theoretical model and we're going to start with this search model and see if this search model does a good job of describing how negotiation happens. So that's it, that's vignette one, it's a way of thinking about negotiation as a form of group problem solving. It's also a way of thinking about group problem solving as a form of negotiation. Because if you have five or 100 people sitting at a table or in a discord server and they're saying, we need to save our company, we need to come up with some plan, some strategy, some product that's going to turn this company around. We're going to have discussions. We're going to come up with a lot of different solutions. And those solutions have to satisfy all our competing needs and interests. So this project is about the intersection of negotiation and group problem solving. Go ahead, Nelson. You're muted.
[ 0:21:26.000 ---> 0:21:32.000 ] Speaker B : Sorry. So basically this is ongoing research that you're working on, right?
[ 0:21:32.000 ---> 0:21:33.000 ] Speaker A : Yep.
[ 0:21:33.000 ---> 0:22:13.000 ] Speaker B : Do you have any ideas how and I think you started kind of like touching a little bit upon this, but how it will be applicable. Because in some ways in the day to day life, I'm not going to take an Excel spreadsheet with 50 different fields to try to figure out how to have a discussion with a person that is in front of me. So I saw that you mentioned AI agent. Maybe we could have a little bit like AI agent that would listen to the conversation, know the topic, and kind of be like mediators. How do you see the application of this research?
[ 0:22:13.000 ---> 0:47:42.000 ] Speaker A : Yeah, it's a great question. So there's a couple of different areas. So I'm a mediator, I'm a facilitator. I want to come up with a process, an intervention that I can bring into a group and say, this process or this piece of technology will help you improve your outcomes. We can't engineer solutions for a group behavior until we understand the group behavior. So this is some really basic science aimed at developing models that will allow us to predict if you pull on these different levers. So if indeed the search model is useful at describing this scenario that gestures its solutions, it suggests that the reason groups fail is because they get stuck on suboptimal outcomes. Other things are this framework can be useful. This is what I was gesturing at yesterday, by the way, artem and Andrea, you can use this framework to create a symbolic understanding of how negotiation happens, have an AI harness that and try to propose solutions to a group. There's a lot of reasons to be concerned about that, but it's a reason you think you could do. And by the way, what we teach our students is in fact, to open up an Excel spreadsheet and make a payoff sheet for every serious decision you make. Because if you don't know what your preferences are, how can you choose between the different outcomes? So this is really basic research aimed at quite a few possibilities for interventions. So I'm going to speed things up a little bit. I hadn't accounted for that kind of ten minute intro. So again, if you want more details, what I'm covering for the rest of this is stuff that's all written up. There are papers and publications, so I can send you the really gruesome details if you want it. Okay? So my next question is going to be about predicting. So I have behind me this jar of candies. This is actually something I'm very proud of, that jar of candies. It got me my job. So let's say I'm asking you to guesstimate how many M and Ms are in that jar of M and Ms. So that's the task I would ask you to do. I would ask you to estimate how many M and Ms are in the jar of M and Ms. So task two is predicting. So we're taking this notion of group decision making. We're negotiating, we're deciding what strategy is right for our company, and we're trying to navigate all these different competing needs and interests. So that's why decision making is a lot like negotiation. But even as we're doing this, we're making predictions. So we're talking about what our preferences are. But also, someone has a new product, I need to evaluate how many units of that product will sell, or I design this new security mechanism, what probability is there that someone can crack this security? Right? So we're making a lot of predictions. So what I'm going to talk about now is really isolating a super micro component of group decision making, and that is belief formation. I'm going to say all beliefs are forecasts. So things that I'm interested in are questions like how many jobs will this policy create? How much money is product Co worth? How much water is on the moon? Right? So it's a belief how much water is on the moon, but it's also a forecast. It says if we're to go measure the water on the moon, what will the answer turn out to be? Or I used to hire people for a customer service team, so your call may be monitored or recorded. Well, that was my budy Scott. He sat behind me and recorded the calls and monitored them and gave people scores. And if your score was below a four for three months in a row, you got fired. Your score was above a four, you got to keep your job. So when I was hiring people, all I had to do is predict, what score will this candidate get? Okay, so I'm interested in how can we get really accurate forecasts? And there's this really cool mathematical and empirical property known as the wisdom of crowds. The wisdom of crowds is empirically driven in that if you go and ask a whole lot of people how many jelly beans are in the jar or how many units of this product will sell, turns out if you ask a whole lot of just regular old people off the street questions and take the average. That average answer is often more accurate than expert opinions. We also have a mathematical guarantee that the collective error, so the error of that group average. So if I take the error or I take the average answer, I'm going to call that the collective answer, mathematically guaranteed to be lower than the average individual, which means if I take the group average, it's guaranteed to be more accurate than just randomly selecting an individual and asking what they think. So this is the wisdom of crowds. There's a whole ton of research on this. What I'm interested in is, once you have this group with this nice, accurate crowd answer, what happens when they start talking to each other? Right? Because we don't just independently contribute answers on survey questions, we talk to each other, we're making decisions collectively. There's a bit of a paradox. So on the one hand, communication generates social learning, on the other hand, communication generates social herding. So which one's going to win? Again? We can use theoretical models to start forming hypotheses and think carefully about exactly what's going on. So the theoretical question is, how do groups form opinions? So I have adopted from my research, and this is a very popular model, model that was studied in the 70s by a statistician, Mars de Groot. The model is very simply, every person starts with an estimate, they learn about the estimates of some other people in the group, could be a subset, could be everybody. And I adopt a weighted average. So by weighted average, I mean maybe I'm placing a lot of weight on Nelson's belief, a little bit of weight on Daniel's belief, a lot of weight on Andrea's belief, so I don't have to treat everybody equal. That also can mean I place no weight on other people's beliefs than all weight on my own belief. This is a very flexible model. If you repeat this indefinitely, groups will converge on a single shared consensus belief. That's asymptotic. I don't believe we live in an asymptotic world, but that gives us some direction, the trajectory of the group belief. And then there's some more technical stuff I'm going to skip over. So the point is that people's weights are based on their centrality in the social network, where the social network is who talks to who. So I talk to Nelson and Daniel. Daniel talks to Andrea. And Artem. Artem talks to Christopher and Flavia. So even though I'm not talking to Flavia, I talk to Daniel, who talks to Artem, who talks to Flavia. Information can flow through the network, right? And the more people I talk to, the more influential I'm going to be on the group's final estimates. That's what the model predicts. It's also very intuitive, right? The more people talk to me, the more people are going to update towards my belief. So we can now characterize social networks based on the distribution of centrality. Maybe Nelson is really central, I'm not central at all. And we can use a mathematical metric called centralization. There's a lot of different ways to measure centralization. One very easy way to measure centralization is just on the genie coefficient. So that's that classic economic inequality. So you can consider a highly centralized network to be one with very unequal in influence, one really well connected person and a lot of peripheral people, a fully decentralized network. And this is decentralized in the network sense, not in the dow sense. The slightly different usage of the word decentralization. A fully decentralized network is one in which everybody's equally influential, maybe everybody's connected to four other people, or maybe everybody's connected to everybody. And now we can predict that the fully decentralized network will converge on the beliefs of. The exact average because everybody's equally weighted. The fully decentralized network will just converge on that crowd average. Which is a good thing, because that crowd average is accurate, right? The centralized network is going to converge on what, the opinions of the central people, right? So the decentralized network is preserving the wisdom of crowds. The centralized network is converging really on the wisdom of the few. So you're losing the wisdom of crowds because you're just getting the opinions of those few really loud, outspoken, talkative people. All right? So that now gives us a hypothesis we can test. Decentralized networks will preserve the wisdom of crowds when people talk, centralized networks will lose the wisdom of crowds. So I did an experiment. There's actually a lot of experiments like this. Now, they all follow the same basic paradigm. I'm going to talk about a few results. In this paradigm, we ask people to give a numeric estimate. They give an initial independent answer, then they communicate through some communication process. It can be just seeing the answers of other peers, it can be a chat room. And then they give a final answer. So we're just going to compare the initial answer and the final answer and we're going to say, did the group get more accurate? So we started by just comparing fully decentralized networks with fully centralized networks dominated by those one really well connected people. As expected, the maximally centralized groups were drawn to the central individual. But much to my surprise, the decentralized groups did not simply preserve the wisdom of crowds, they actually became more accurate. I was surprised by this. It turns out, at least in this experiment, people who were more accurate are also more stubborn. You can interpret that as confidence if you want. There's some other data. Yes, this is very related to the Delphi method. In a longer version of this, I go into that in detail. So, yeah, basically we can say that at least in our data set, there was a confidence accuracy correlation that was positive, more confident people were more accurate. That tends, as it turns out, to show up repeatedly. There tends to be a confidence accuracy correlation in a lot of these lab studies. It's not a requirement, which means the effect of communication is driven not only by the network structure, but by this confidence accuracy correlation. So we started with this group, this kind of collective, this wisdom. Crowds paradox, groups can lead, communication can lead to social learning. Communication can lead to social herding. So where I'm at now is I'm going to say, yeah, there's not a fixed effect. We can't simply ask, is communication good or bad? We have to take into account the network structure. We have to take into account features of the group itself, whether their confidence calibrated. So it's not a simple question of is communication helpful or harmful? It's a question of is my group going to be one where communication is helpful or harmful. I'm going to add one final wrinkle. I'm going to go through this very quickly because of the time, please forgive me, I can go through more details if anybody's interested. There's one final wrinkle. It's not just about the group, it's about the actual question that you ask. Because different questions. If I ask you how many jelly beans are in the jar, I might get a normal bell curve distribution of answers. If I ask you how much is this product going to sell? I could get a completely different statistical distribution of answers. We previously had no reason to think that the statistical distribution mattered. It's all about the network structure. It's all about the confidence, accuracy correlation. It turns out this is now back into ongoing research. Even confidence accuracy correlation, even if you have a really well calibrated group, that is not enough to ensure that you will preserve or even improve the wisdom. Cause I'm going to give you a super brief conceptual proof of why the statistical distribution matters. Consider here. This is a visual illustration of a statistical distribution. The black line shows the popularity of different beliefs. The red line shows the group mean the average. The dashed blue line shows the actual true answer. So in this hypothetical distribution, 80% of people are on the left hand side of the average. This is a skewed distribution. 20% of people are on the right hand side of the average. Which means if you randomly grab a person and just give them a little bit of influence, there's an 80% chance the group is going to be nudged to the left and a 20% chance the group is going to be nudged to the right. But whether it moves to the left or the right determines whether it moves away from the truth or towards the truth. So it turns out the statistical distribution determines the probability that a randomly selected person will make the group better or make the group worse. I'm going to add one final wrinkle. When we have conversations, some people talk more than others. Hopefully that's an assumption you can get behind. Some people talk more than others and the more talkative, people are more influential on the group's outcome. I can actually show this in chat room data. We put people in a chat room, we had them predict things. Hang out in a chat room and predict again the prediction of the most talkative person determined the trajectory of the group belief. Which means if you have a chat room and the person's talkativeness is totally random, not related to their accuracy, if you have people in a chat room and it's this type of distribution, this 80 to 20 distribution, there's an 80% chance that the group will move to the left and a 20% chance the group will move to the right. Which means the effective communication is not determined by the social network, not determined by people's confidence calibration, but simply by the statistical distribution, which could be different for different questions. Which means if you ask a question about jelly beans or if you ask a question about product viability, one question may benefit from discussion and another question might get worse from discussion. So that's something to consider. Basically what I'm saying is it's actually super unreliable and I could not possibly tell you whether communication is going to help or harm for your group. That's where I'm at right now, is this sort of uncertainty. This is a very limited theoretical model. As you've noticed. I've made a lot of assumptions. It's all based on this very simple numeric exchange model. I do have data of people in chat rooms, so we know it works for more natural human interaction. But even chat rooms, they're not the most brilliant deliberations in the world. So I'm still hoping that a really high quality deliberation. And I'm actually currently looking or about gathering data from delphi methods to see if that basically makes this effect go away. I'm not hopeful that it will, but hopefully it will. I think I want to save Deliberation and show that the issue is not with people, but with the experimental procedures. In the end, it's probably going to turn out to be both. I want to give one final wrinkle. Be really careful about binary choice. So remember me as the hiring manager for that customer service team. I said my hiring decision is simply a prediction. What quality assurance score will they get? But it's not just a prediction of what quality it's not. Is it 4.3 or 4.2 or five? It's will it be above or below a four? It's a threshold question. It's not really a numbers question. It's a yes no question. And the thing about binary choice is if I have a committee and we have a conversation and we say, hey, what do you think? I think they're a five, I think they're a three. I think they're a 2.5. Let's say we're well calibrated and all the statistics are in our favor and our crowd average, that average answer of that person's quality assurance score is getting more accurate over the course of discussion. Okay, cool. Collective intelligence is working. Our average answer is getting more accurate. Even as that average answer is getting more accurate. The vote on yes no, are they above or below a four can get less accurate. So that's basically the punchline of this is the actual decision itself is decoupled from that wisdom of crowds metrics. The punchline here is that you have to be really careful in theorizing and thinking about every stage of the decision process. So I started with this really broad type of decision, complex multiparty negotiation. I zoomed in on one really specific element of that belief formation. Then I took a tiny baby step from belief formation to voting on that exact belief, and even that tiny baby step from belief formation devoting on that belief throws in a whole lot of wrinkles, which just says we need to really be comprehensive about how we are theorizing group decisions. And this is why me, personally, I try to develop formal computational models to represent these messy, complex human behaviors, because these formal computational models highlight things you might have missed. So this result here started with, well, actually, by accident. I was trying to show that the decision got better. I ran a couple simulations on the numbers, was very disappointed to show that the decision got worse, and then we ran some experiments to test it. There's a very short Harvard Business Review article that summarizes this and has a little proof of concept example. If you want to get into this. All right, I'm going to skip my confession. I already sort of went into that. I'm going to get to one final thing. So I've been talking about decisions that are really well defined. Here's a negotiation. You have to reach an agreement. Here's a number. You have to come up with a number. But collective decisions often happen without anybody making any decision at all, or at least not intentionally. So the third activity I would do if we were in person, I would give you all a bunch of colored cards red, green, blue, yellow, whatever. Your job would be to randomly walk up to a person. You go, one, two, three, go. You try to pull the same color. It's called the psychic game. Like, am I psychic? Can I predict what color Nelson's going to pick? And if you have people doing that, eventually they all magically start picking the same color. This is called a coordination game, classic game theory stuff. So it's a coordination game. It's a model for how social conventions emerge. And the reason it works is because I'm observing what other colors people are picking. And if I notice red is more popular than blue, I'm going to start showing red. So this is a model we use for explaining the emergence of conventions. Things like language, right? We don't care what word we use, as long as we use the same word. Railroad gauge is an interesting technological example. In the early development of railroads, there were all these different companies doing their own railroads. This is more in America. But they were all far apart. Eventually they started integrating the systems. Railroad gauge is interesting because you actually do care what railroad gauge. Some have different technical properties. Some are safer than others, some are faster than others. So we're simultaneously trying to match our peers while also getting the highest payoff. Social media platforms, right? I don't really care which social media platform I use, as long as they match my peers. Coding language. I don't care if I use Python or R, as long as I can share my code with my collaborators, right? So language, maybe we don't care. But with these other examples, we not only want to coordinate, but we also want to coordinate on the best possible outcome. So my question is, why don't we converge on best possible outcomes? Classic economic theory would actually predict that we do converge on the best possible outcome. But you look around the world, you know that we don't converge on the best possible outcome. So a partial answer that also comes from economic theory is lock in effects, right? Python is stupid, but everybody's using Python. So even though we all agree that Python sucks, nobody's ever going to stop using it because we're all locked into it. Or the QWERTY keyboard, right? Everybody hates the QWERTY keyboard. It's slow to learn. There are better keyboards out there, but we're never going to start using them because everybody's using the QWERTY keyboard or the railroad gauge. Maybe there was a super amazing railroad technology that was developed in Bumblefuck, but because it was really far away, everybody else converged on this more popular but suboptimal outcome. So this is a model that I've done some empirical work on that's been more about tipping points in social conventions. So once a convention is established, how many people does it take to use something different to bring in a new convention? I'm interested in this question of what makes groups more or less likely to converge on the optimal convention in the first place. So again, I'm looking at network centralization. I'm comparing this convergence on centralized and decentralized centralized networks. And to summarize the theoretical results, more highly centralized networks, they converge faster, but they are less optimal. However, we don't actually have a speed optimality trade off networks that are denser. So more people connected to more people are both fast and optimal. So this example does a couple of things. One, I want to highlight that this is a kind of collective decision. Nobody said, well, somebody did, but we didn't collectively sit down and say, okay, what coding language should we use? Hey, everybody want to use Python? We're all cool with Python. Let's all use Python. It was just an emergent byproduct of various social factors. I realized the real world is a lot more complex than models. Like Python also was a learning language, so everybody learned it when they were young and it became popular. But this gives us a way of thinking about how these little just my interaction with my peers. I'm just trying to use my peers. I'm just trying to use the same coding language as my colleagues across the hall. These local interactions of just trying to personally optimize lead to emergent or unintentional decisions at the group as a whole. And we once again see this theme that centralization is bad. And in both cases, it's because centralization means there are really well connected individuals in the network. You might think that well connected individuals for conventions also have a really wide view. So they could use their wide view to find the good solutions and make them popular, like they use their platform. But the problem is, at the same time, whatever solution they come up with, because they're so well connected, is immediately going to become popular. And it turns out, again, we're converging on the wisdom of the few and not the wisdom of the crowd as a result of centralization. This is a big old advertisement for decentralization in the network sense, but a lot of the similar properties carry over to decentralization in other senses. So, to summarize, I've talked about three classes of collective decisions. You need to agree on a number. How should we set this budget? You need to guess a number. How much is this product worth? You need to choose a number. We're all just picking numbers to match with our peers. Eventually, we're going to converge. There's this sort of back and forth between empirical reality and theoretical thinking that I'm using to think about these always driven by the empirical reality, always looking for a concrete theoretical model. These theoretical models then lead back into empirical predictions, which we test. These empirical predictions could be purely scientific to test our model. They also could be intervention oriented. So once we know centralization is bad, you can say, okay, I'm going to design my group around a decentralized network, right? And yet I'm putting a question mark on that because we've also seen that each of these results is highly contingent on your assumptions, on the network structure, on the features of the task itself. So we can't just come up with blanket rules that say you should run every group decision. This way. You really need to consider the nature of the group, the nature of the decision, the nature of the particular task at hand. You need to consider all of these things to think carefully about how to optimize your group decisions. Those are my three vignettes. Thank you all so much for your patience as I gradually accelerated. I'm happy to stick around for we have at least two minutes if people have further discussion, or longer if anybody wants to stick around, if we've got the.
[ 0:47:44.000 ---> 0:48:44.000 ] Speaker C : Yes. Yes. Really, really excellent presentation, Joshua. Really a lot of thought on my end. I could speak. So, yeah, we definitely want to open the door for Q A. But yeah, let's go ahead and I guess I'll go ahead and start with the first. You know, you mentioned that depending on a deliberation, the truth could either be skewed in the opposite direction or toward the truth. So I'm just curious, is there any maybe hypothesis or anything that you've observed about the characteristics of maybe the people deliberating that moves it more toward the truth? Maybe we have experts. Maybe it's a deliberation between subject matter experts, people who have hands on experience with this topic at hand. Because I'm just curious because you mentioned randomly selecting someone for a deliberation might cause a lot of negative outcomes. Just kind of want to curious to get your further thoughts on that.
[ 0:48:44.000 ---> 0:51:03.000 ] Speaker A : Yeah, so there's a couple of questions and when I talk about randomly selecting, I went through that really quickly. That's because my talkativeness has nothing to do with the fact that I have the right answer. It has to do with the fact that I come from a very large family. So if you ask me a question I know a lot about, I'm going to be talkative. If you ask me a question I know nothing about, I'm going to be talkative. So randomly selecting there is like a statistical notion. I'm not saying the groups flip a coin and pick a person to be influential. It's a statistical way of it's effectively random in contrast. So talkativeness is effectively random, in contrast, stubbornness. So how much am I going to change my belief that turns out to be correlated with confidence. So one thing to look at for a group is that confidence calibration you can see is my group one where you could also look at talkativeness. Calibration, maybe you could have a group culture. I'm just thinking off on my feet here, a group culture that says don't talk unless you're really confident. Because if we have a confidence accuracy correlation, that could lead to a talkativeness accuracy correlation. The problem is, as I mentioned, even a confidence accuracy correlation is not sufficient to always save the group. Depends on how well correlated is. The fact of the matter is that it's pretty unpredictable whether Deliberation is going to help or harm it seems on average to help across a bunch of experimental studies. But who knows if these experimental studies are representing the distribution of things that your group might encounter. So I would say the best bet for determining an accurate number, if you're just trying to come up with an accurate number, is to survey everyone, ask them how confident they are, let them have a conversation, see how talkative they are, then throw all that into some kind of ridge regression or lasso kind of machine learning algorithm and use that to extract some sort of black box prediction, which is what? Groups like Metaculous, which is an online forecasting website. That's basically what they do. They just have a trained algorithm that says, hey, we've got all this data from the website, how does that predict the outcome? And I would say, Calibrate, that for your group because it's going to be different for every group.
[ 0:51:04.000 ---> 0:51:17.000 ] Speaker C : Excellent, excellent. Very good advice. So it looks like we have question from Andrea asking what is density in a network? Interactions and nodes.
[ 0:51:18.000 ---> 0:51:35.000 ] Speaker A : Yes, sorry, I didn't define that. I was going pretty quickly. So a super dense network is one where everybody knows everybody or everybody interacts with everybody. A super sparse network is the actual world we live in because there's 7 billion people on Earth. But I only know, I don't know 100 of them or whatever.
[ 0:51:35.000 ---> 0:51:40.000 ] Speaker C : Yeah, got you. I know that Daniel had his hand up earlier.
[ 0:51:44.000 ---> 0:51:47.000 ] Speaker B : No Nelson gofrett.
[ 0:51:47.000 ---> 0:51:48.000 ] Speaker C : Sure.
[ 0:51:50.000 ---> 0:52:57.000 ] Speaker B : So this is super interesting. I wonder how that connects with the idea of timing. Let's say you have a group, you have an organization, especially when you look at the realms of dows. What I've seen over the years is that very often when dows start too decentralized, they tend not to go anywhere. And there's probably some kind of optimal curve of starting actually very centralized around somebody's vision at the beginning. And then once it gets some kind of cohesive, like enough movement, enough momentum, enough to be fair resources, monetary resources, then there is a moment where it can actually more and more decentralized to actually become something sustainable and grow and fulfill its objective. So in terms of being centralized and decentralized, is there something as an optimum moment, an optimum timing of it? Have you ever gotten something like that?
[ 0:52:58.000 ---> 0:58:14.000 ] Speaker A : No. And I think that's a really interesting point. It's something I think about. This is all my academic science geeky stuff, but I also have worked in communities. I'm on the board of a charity that is a community. I hang out with Newspeak House. Right. I used to help run a collective arts venue. Right. There are so many challenges we face as groups organizing that have nothing to do with belief, accuracy, negotiation or coordination. I mean, coordination is a big part of it. These three kind of vignettes highlight a few different aspects of group behavior. But the real challenge as an engineer, I treat management as an engineering. The real challenge as an engineer is that these three models capture three of like 150 processes that are going on your group. So that's one thing is that's my just kind of like it's like asking Isaac Newton to build a rocket ship because he completed the principia. So we're sort of science wise, we're at the level of 16th century physics. We've got these super basic clunky models. And I also want to highlight that there's a couple of different like the word decentralized means different things in different contexts. So I can have an absolute that's decentralized where everybody discusses with a few peers how many jelly beans there are in the jar. But let's say we have a Dow that's run by a smart contract that says, okay, after everybody makes their independent estimates, this smart contract is going to take the average and it's going to buy that jar of jelly beans if the average crowd answer is more than 100. So that is a centralized decision in the sense that the decision itself, the way the problem is set up, the notion that the threshold is 100, the algorithm for taking that input and turning it into a decision is very centralized. So the group is decentralized in its network structure of information exchange, but the actual decision architecture is highly centralized in the more colloquial sense. Right. So maybe there is a happy medium. Maybe it's about being centralized in some ways while being decentralized in other ways. I'm not sure. And again, just acknowledging that you're invoking so many concepts that aren't really reflected in these theoretical models. People will do this. People will do this with their science. It would be a little irresponsible of me to say this model of belief formation tells you everything you need to know about doubts. Be wary of anyone who tells you from one model or result they can tell you how to run your organization. I'm not going to do that. It's why I don't get paid as a consultant. But yeah, Andrea, go ahead. So I'm really interested in how the structure of the choices, the choice structure, is impacting the quality of all of those things. Are you feeling like you're getting to the point of having a taxonomy of here are the safer or better choice structures in these contexts or in this choice structure, use this kind of watch for this issue? No, I mean, there are definitely people out there making taxonomies. There are people who put together review articles on collective intelligence that try to do, like, a meta study and synthesize across everything and give you tables that say, oh, if you're in this kind of space, use this kind of process. I am super skeptical of those for all of the reasons I just mentioned. Because even as something as unobservable as this statistical distribution, we don't know. Yeah, or like one of the things about this fitness landscape is I think we don't let the perfect be the enemy of the good. So when I've got my practitioner hat on, I come up with the best process I can. So I'm working with this company I'm consulting on. They're trying to boost innovation. Right. We don't really have any scientific model for how innovation happens in any it's more like Newtonian, right? You can't build a rocket ship, but they've got to make a decision today so you can make your best guesstimates. So one thing that I think about a lot as a practitioner that we should think about in this harmonica development is if you have a complex problem that's going to require a very different style of facilitation than a simple problem. Because a simple problem you can get through very quickly. Okay, just keep iterating. Keep iterating. We'll get to the peak. A complex problem is one where you really want to take your time, dig into it, have those deep discussions. Right. So we're starting to get at some rules of thumb, but I'm always really reluctant to say them too confidently. Depends on whether I'm wearing my practitioner hat or my scientist hat. Because as a practitioner, like, I was taught a method for mediation. I have no laboratory evidence that it works, but I am very confident that it does work because I've been doing it for years. Right, so we can kind of triangulate a little bit and come up with the best designs we can. But I have to just be careful about how I frame that.
[ 0:58:16.000 ---> 0:58:33.000 ] Speaker C : So it looks like we have a question from Libby. What are your thoughts on innovative outcomes within decentralized voting methods? Do you believe there is a risk for only safer decisions passing stunting, the more creative?
[ 0:58:35.000 ---> 1:00:02.000 ] Speaker A : That's really an interesting question. Yeah. Within decentralized voting methods. So you highlight this notion that I'm going to say absolutely I could see processes that risk passing safer decisions rather than the more creative ones. The framework I would think about that for, I would use this framework, I started with the negotiation framework to think about that because what you've got is actually two issues that you're evaluating a decision on. Some people are more risk averse and they will prefer the safer solution. Some people are more risk loving and they will prefer the creative solution. So you're actually optimizing on different dimensions. So whether your group goes for one or the other is going to depend a little bit on their preferences. But I absolutely think that different processes can lead to different preferences. I love that framing of risk aversion. I would love to steal that or if we could work on that together. I think that the framework I'm developing could be used to answer a question like that. I wouldn't be surprised if there's some research on it already, but I doubt that there's much in this kind of formal theoretical space just because people in this world are at such basic questions.
